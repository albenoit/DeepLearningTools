<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />
<link rel="index" title="Index" href="genindex.html" /><link rel="search" title="Search" href="search.html" /><link rel="next" title="deeplearningtools.tools subpackage" href="reference_tools.html" /><link rel="prev" title="Test script" href="unit_test.html" />

    <link rel="shortcut icon" href="_static/logo_listic.png"/><!-- Generated with Sphinx 6.2.1 and Furo 2023.05.20 -->
        <title>deeplearningtools.helpers subpackage - DeepLearningTools 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo.css?digest=e6660623a769aa55fea372102b9bf3151b292993" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css" />
    
    


<style>
  body {
    --color-code-background: #2E3440;
  --color-code-foreground: #d8dee9;
  --font-stack: Roboto, sans-serif;
  --font-stack--monospace: Open Sans, monospace;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<div class="announcement">
  <aside class="announcement-content">
     <em>Deeplearningtools is currently in development.</em> 
  </aside>
</div>

<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="index.html"><div class="brand">DeepLearningTools 0.1.0 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo only-light" src="_static/main_light.png" alt="Light Logo"/>
    <img class="sidebar-logo only-dark" src="_static/main_dark.png" alt="Dark Logo"/>
  </div>
  
  <span class="sidebar-brand-text">DeepLearningTools 0.1.0 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="features.html">Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="example.html">Examples and demonstrations</a></li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="reference.html">Reference manual</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Reference manual</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 current has-children"><a class="reference internal" href="reference_index.html">DeepLearningTools package</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of DeepLearningTools package</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="main_script.html">Main subpackage</a></li>
<li class="toctree-l3"><a class="reference internal" href="unit_test.html">Test script</a></li>
<li class="toctree-l3 current current-page"><a class="current reference internal" href="#">deeplearningtools.helpers subpackage</a></li>
<li class="toctree-l3"><a class="reference internal" href="reference_tools.html">deeplearningtools.tools subpackage</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">Frequently asked questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="contribute.html">Community involvement and contributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="version.html">Release notes</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="edit-this-page">
  <a class="muted-link" href="https://github.com/albenoit/DeepLearningTools" title="Edit this page">
    <svg aria-hidden="true" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <path d="M4 20h4l10.5 -10.5a1.5 1.5 0 0 0 -4 -4l-10.5 10.5v4" />
      <line x1="13.5" y1="6.5" x2="17.5" y2="10.5" />
    </svg>
    <span class="visually-hidden">Edit this page</span>
  </a>
</div><div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section class="left" id="deeplearningtools-helpers-subpackage">
<h1>deeplearningtools.helpers subpackage<a class="headerlink" href="#deeplearningtools-helpers-subpackage" title="Permalink to this heading">#</a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this heading">#</a></h2>
</section>
<section id="module-deeplearningtools.helpers.alignment">
<span id="deeplearningtools-helpers-alignment-module"></span><h2>deeplearningtools.helpers.alignment module<a class="headerlink" href="#module-deeplearningtools.helpers.alignment" title="Permalink to this heading">#</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.alignment.align_network">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.alignment.</span></span><span class="sig-name descname"><span class="pre">align_network</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">extend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inplace</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/deeplearningtools/helpers/alignment.html#align_network"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.alignment.align_network" title="Permalink to this definition">#</a></dt>
<dd><p>Aligns a network to another network referred to as the target network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> – The source network (tuple or np.ndarray) of shape (n_layers, n_units, …).</p></li>
<li><p><strong>Y</strong> – The network to be aligned (tuple or np.ndarray) of shape (n_layers, n_units, …).</p></li>
<li><p><strong>distance</strong> – The distance metric used to compute the cost between two units.
If None, the L2 distance will be used.
If a string, the corresponding pre-defined distance metric will be used.
If a custom callable, it should accept two np.ndarray arguments and return a float.</p></li>
<li><p><strong>extend</strong> – If True, consider the negative layer in Y for alignment.</p></li>
<li><p><strong>verbose</strong> – If True, print unit changes size during alignment.</p></li>
<li><p><strong>inplace</strong> – If True, align Y directly in place. If False, create a copy of Y for alignment.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The aligned network, alignment costs, and size of aligned layers.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[np.ndarray, np.ndarray, np.ndarray]</p>
</dd>
</dl>
<p>Author: Youssouph Faye.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.alignment.gradient">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.alignment.</span></span><span class="sig-name descname"><span class="pre">gradient</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="reference internal" href="_modules/deeplearningtools/helpers/alignment.html#gradient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.alignment.gradient" title="Permalink to this definition">#</a></dt>
<dd><p>Calculate the gradient dissimilarity between two arrays.</p>
<p>The gradient dissimilarity between two arrays, x and y, is a measure of their dissimilarity based on the signs of their corresponding elements.
The gradient dissimilarity can be calculated as the number of elements in the arrays where the product of the corresponding elements is negative:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[gradient = \sum_i [x_i \cdot y_i &lt; 0]\]</div>
</div>
<p>where:</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x_i\)</span> and <span class="math notranslate nohighlight">\(y_i\)</span> are the corresponding elements of arrays x and y,</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>np.ndarray</em>) – The first array.</p></li>
<li><p><strong>y</strong> (<em>np.ndarray</em>) – The second array.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The gradient dissimilarity.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.alignment.l1">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.alignment.</span></span><span class="sig-name descname"><span class="pre">l1</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="reference internal" href="_modules/deeplearningtools/helpers/alignment.html#l1"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.alignment.l1" title="Permalink to this definition">#</a></dt>
<dd><p>Calculate the L1 distance between two arrays or vectors.</p>
<p>The L1 distance, also known as the Manhattan distance or taxicab distance, between two arrays (or vectors) is a measure of the absolute difference between 
the corresponding elements of the arrays.
The L1 distance between two arrays, x and y, of equal size, can be calculated as follows:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[L1_{distance} = \sum_{i=1}^{n} |x_i - y_i|\]</div>
</div>
<p>where:</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x_i\)</span> and <span class="math notranslate nohighlight">\(y_i\)</span> are the corresponding elements of arrays x and y,</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>np.ndarray</em>) – The first array.</p></li>
<li><p><strong>y</strong> (<em>np.ndarray</em>) – The second array.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The L1 distance.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.alignment.l2">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.alignment.</span></span><span class="sig-name descname"><span class="pre">l2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="reference internal" href="_modules/deeplearningtools/helpers/alignment.html#l2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.alignment.l2" title="Permalink to this definition">#</a></dt>
<dd><p>Calculate the L2 distance between two arrays or vectors.</p>
<p>The L2 distance, also known as the Euclidean distance, between two arrays (or vectors) is a measure of the distance between these two points in Euclidean space. 
The distance L2 between two arrays, x and y, of equal size, can be calculated as follows:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[L2_{distance} = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}\]</div>
</div>
<p>where:</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x_i\)</span> and <span class="math notranslate nohighlight">\(y_i\)</span> are the corresponding elements of arrays x and y,</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>np.ndarray</em>) – The first array.</p></li>
<li><p><strong>y</strong> (<em>np.ndarray</em>) – The second array.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The L2 distance.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.alignment.pearson">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.alignment.</span></span><span class="sig-name descname"><span class="pre">pearson</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sort</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="reference internal" href="_modules/deeplearningtools/helpers/alignment.html#pearson"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.alignment.pearson" title="Permalink to this definition">#</a></dt>
<dd><p>Calculate the normalized Pearson correlation between two arrays, the measure of similarity between two variables [0:1].</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>np.ndarray</em>) – The first array.</p></li>
<li><p><strong>y</strong> (<em>np.ndarray</em>) – The second array.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The normalized Pearson correlation.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.alignment.pearson_cost">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.alignment.</span></span><span class="sig-name descname"><span class="pre">pearson_cost</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sort</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="reference internal" href="_modules/deeplearningtools/helpers/alignment.html#pearson_cost"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.alignment.pearson_cost" title="Permalink to this definition">#</a></dt>
<dd><p>Calculate the Pearson correlation coefficient between two arrays, the measure of dissimilarity between two variables [-1:1].</p>
<p>It quantifies the strength and direction of the linear association between the variables.
The Pearson correlation coefficient can be calculated as:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[r = \frac{{\sum((x_i - \overline{x})(y_i - \overline{y}))}}{{\sqrt{{\sum(x_i - \overline{x})^2}} \cdot \sqrt{{\sum(y_i - \overline{y})^2}}}}\]</div>
</div>
<p>where:</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\overline{x}\)</span> and <span class="math notranslate nohighlight">\(\overline{y}\)</span> are the means of arrays x and y respectively,</p></li>
<li><p><span class="math notranslate nohighlight">\(x_i\)</span> and <span class="math notranslate nohighlight">\(y_i\)</span> are the corresponding elements of arrays x and y,</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>np.ndarray</em>) – The first array.</p></li>
<li><p><strong>y</strong> (<em>np.ndarray</em>) – The second array.</p></li>
<li><p><strong>sort</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – Whether to sort the arrays before calculating the correlation coefficient.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The Pearson correlation coefficient.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.alignment.pearson_sorted">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.alignment.</span></span><span class="sig-name descname"><span class="pre">pearson_sorted</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="reference internal" href="_modules/deeplearningtools/helpers/alignment.html#pearson_sorted"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.alignment.pearson_sorted" title="Permalink to this definition">#</a></dt>
<dd><p>Calculate the normalized Pearson correlation between two sorted arrays.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>np.ndarray</em>) – The first sorted array.</p></li>
<li><p><strong>y</strong> (<em>np.ndarray</em>) – The second sorted array.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The normalized Pearson correlation for sorted arrays.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.alignment.spearman">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.alignment.</span></span><span class="sig-name descname"><span class="pre">spearman</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="reference internal" href="_modules/deeplearningtools/helpers/alignment.html#spearman"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.alignment.spearman" title="Permalink to this definition">#</a></dt>
<dd><p>Calculate the normalized Spearman correlation between two arrays.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>np.ndarray</em>) – The first array.</p></li>
<li><p><strong>y</strong> (<em>np.ndarray</em>) – The second array.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The normalized Spearman correlation.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.alignment.spearman_cost">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.alignment.</span></span><span class="sig-name descname"><span class="pre">spearman_cost</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sort</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="reference internal" href="_modules/deeplearningtools/helpers/alignment.html#spearman_cost"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.alignment.spearman_cost" title="Permalink to this definition">#</a></dt>
<dd><p>Calculate the Spearman correlation coefficient between two arrays.</p>
<p>The Spearman correlation coefficient measures the strength and direction of the monotonic relationship between two variables. 
It is a non-parametric measure that assesses the similarity of the ranks of the corresponding elements in the arrays.
The Spearman correlation coefficient can be calculated as:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[r = 1 - \frac{6 \sum d_i^2}{n(n^2 - 1)}\]</div>
</div>
<p>where:</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(r\)</span> is the Spearman correlation coefficient,</p></li>
<li><p><span class="math notranslate nohighlight">\(d_i\)</span> is the difference in the ranks of corresponding elements,</p></li>
<li><p><span class="math notranslate nohighlight">\(n\)</span> is the number of elements in the arrays.</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>np.ndarray</em>) – The first array.</p></li>
<li><p><strong>y</strong> (<em>np.ndarray</em>) – The second array.</p></li>
<li><p><strong>sort</strong> (<em>bool</em><em>, </em><em>optional</em><em> (</em><em>default=True</em><em>)</em>) – Whether to sort the arrays before calculating the correlation coefficient.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The Spearman correlation coefficient.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.alignment.spearman_sorted">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.alignment.</span></span><span class="sig-name descname"><span class="pre">spearman_sorted</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="reference internal" href="_modules/deeplearningtools/helpers/alignment.html#spearman_sorted"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.alignment.spearman_sorted" title="Permalink to this definition">#</a></dt>
<dd><p>Calculate the normalized Spearman correlation between two sorted arrays.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>np.ndarray</em>) – The first sorted array.</p></li>
<li><p><strong>y</strong> (<em>np.ndarray</em>) – The second sorted array.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The normalized Spearman correlation for sorted arrays.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.alignment.stack">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.alignment.</span></span><span class="sig-name descname"><span class="pre">stack</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">units</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="reference internal" href="_modules/deeplearningtools/helpers/alignment.html#stack"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.alignment.stack" title="Permalink to this definition">#</a></dt>
<dd><p>Stack the units array with the bias array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>units</strong> (<em>np.ndarray</em>) – Array of units with shape (num_units, …)</p></li>
<li><p><strong>bias</strong> (<em>np.ndarray</em>) – Array of bias with shape (num_units, …)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Stacked array with shape (num_units, channels+1, weight, height)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.ndarray</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-deeplearningtools.helpers.attention">
<span id="deeplearningtools-helpers-attention-module"></span><h2>deeplearningtools.helpers.attention module<a class="headerlink" href="#module-deeplearningtools.helpers.attention" title="Permalink to this heading">#</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.attention.aconv">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.attention.</span></span><span class="sig-name descname"><span class="pre">aconv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampling_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">8</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/deeplearningtools/helpers/attention.html#aconv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.attention.aconv" title="Permalink to this definition">#</a></dt>
<dd><p>Combine spatial and channel attention weighting.</p>
<p>This function combines spatial and channel attention weighting using the aconv mechanism.
It supports 4D and 5D data as input, respectively image or volume samples.
Actually very similar to squeeze and excitation BUT squeeze is only a subsampling thus forcing local neighbors agregation.
The excitation process then relies on convolutions before the final upsampling and activation step.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_features</strong> (<em>tf.Tensor</em>) – The input features of shape [batch, height, width, channels] or [batch, depth, height, width, channels].</p></li>
<li><p><strong>sampling_rate</strong> (<em>int</em><em>, </em><em>optional</em>) – The downsampling rate applied to the input features, defaults to 8.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The spatially and channel-weighted features of the same shape as the input [batch, height, width, (depth), channels].</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.attention.aconv2">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.attention.</span></span><span class="sig-name descname"><span class="pre">aconv2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sampling_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">8</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/deeplearningtools/helpers/attention.html#aconv2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.attention.aconv2" title="Permalink to this definition">#</a></dt>
<dd><p>Combine spatial and channel attention weighting.</p>
<p>This function combines spatial and channel attention weighting using the aconv2 mechanism.
It supports 2D and 3D data as input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_features</strong> (<em>tf.Tensor</em>) – The input features of shape [batch, height, width, channels] or [batch, height, width, (depth), channels].</p></li>
<li><p><strong>sampling_rate</strong> (<em>int</em><em>, </em><em>optional</em>) – The downsampling rate applied to the input features, defaults to 8.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The spatially and channel-weighted features of the same shape as the input [batch, height, width, (depth), channels].</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
<p>References:REVISED VERSION of “Squeeze-and-Attention Networks for Semantic Segmentation” (https://openaccess.thecvf.com/content_CVPR_2020/html/Zhong_Squeeze-and-Attention_Networks_for_Semantic_Segmentation_CVPR_2020_paper.html)</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.attention.dual_attention">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.attention.</span></span><span class="sig-name descname"><span class="pre">dual_attention</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/deeplearningtools/helpers/attention.html#dual_attention"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.attention.dual_attention" title="Permalink to this definition">#</a></dt>
<dd><p>Combine spatial and channel attention weighting (auto-attention based).</p>
<p>This function combines the spatial and channel attention mechanisms, as described in the paper 
“Spatial Attention in Convolutional Networks for Image Captioning” (<a class="reference external" href="https://arxiv.org/pdf/2001.07645.pdf">https://arxiv.org/pdf/2001.07645.pdf</a>).
It takes 4D or 5D data as input, depending on whether it’s image or volume samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_features</strong> (<em>tf.Tensor</em>) – The input features of shape [batch, height, width, (depth), channels].</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The spatially and channel-wise weighted features of the same shape as the input [batch, height, width, (depth), channels].</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.attention.spatial_attention">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.attention.</span></span><span class="sig-name descname"><span class="pre">spatial_attention</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/deeplearningtools/helpers/attention.html#spatial_attention"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.attention.spatial_attention" title="Permalink to this definition">#</a></dt>
<dd><p>Create a spatial map that highlights regions of interest (auto-attention based).</p>
<p>This function implements the spatial attention mechanism, as described in the paper
“Spatial Attention in Convolutional Networks for Image Captioning” (<a class="reference external" href="https://arxiv.org/pdf/2001.07645.pdf">https://arxiv.org/pdf/2001.07645.pdf</a>).
It supports 2D and 3D data as input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_features</strong> (<em>tf.Tensor</em>) – The input features of shape [batch, height, width, channels] or [batch, depth, height, width, channels].</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The weights of shape [batch, height, width, 1].</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.attention.squeeze_excitation">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.attention.</span></span><span class="sig-name descname"><span class="pre">squeeze_excitation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/deeplearningtools/helpers/attention.html#squeeze_excitation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.attention.squeeze_excitation" title="Permalink to this definition">#</a></dt>
<dd><p>Apply squeeze and excitation auto attention.</p>
<p>This function implements the squeeze and excitation mechanism, as described in the paper
“Squeeze-and-Excitation Networks” (<a class="reference external" href="https://arxiv.org/abs/1709.01507">https://arxiv.org/abs/1709.01507</a>).
It extended supports 2D and 3D data as input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_features</strong> (<em>tf.Tensor</em>) – The input features of shape [batch, height, width, channels] or [batch, depth, height, width, channels].</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The channel-weighted features of the same shape as the input.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-deeplearningtools.helpers.distance_network">
<span id="deeplearningtools-helpers-distance-network-module"></span><h2>deeplearningtools.helpers.distance_network module<a class="headerlink" href="#module-deeplearningtools.helpers.distance_network" title="Permalink to this heading">#</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.distance_network.cosine_distance">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.distance_network.</span></span><span class="sig-name descname"><span class="pre">cosine_distance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">w_a</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">w_b</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="reference internal" href="_modules/deeplearningtools/helpers/distance_network.html#cosine_distance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.distance_network.cosine_distance" title="Permalink to this definition">#</a></dt>
<dd><p>Compute the cosine distance between two sets of weights.</p>
<p>The cosine distance between two sets of weights, w_a and w_b, can be calculated using the following equation:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[{cosine\_{distance}} = 1 - {cosine\_{similarity}}\]</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>w_a</strong> – List of weight arrays for the first set.</p></li>
<li><p><strong>w_b</strong> – List of weight arrays for the second set.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Cosine distance between the two sets of weights.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.distance_network.cosine_similarity">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.distance_network.</span></span><span class="sig-name descname"><span class="pre">cosine_similarity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">first_network</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">second_network</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_align</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cost_distance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="reference internal" href="_modules/deeplearningtools/helpers/distance_network.html#cosine_similarity"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.distance_network.cosine_similarity" title="Permalink to this definition">#</a></dt>
<dd><p>Compute the pairwise cosine similarity between two networks or list of layers.</p>
<p>Referred from the paper “Flexible Clustered Federated Learning” (<a class="reference external" href="https://arxiv.org/pdf/2108.09749.pdf">https://arxiv.org/pdf/2108.09749.pdf</a>).
The cosine similarity is calculated as the cosine of the angle between the two weight vectors:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[{cosine\_{similarity}} = \frac{{w_a \cdot w_b}}{{\|w_a\| \cdot \|w_b\|}}\]</div>
</div>
<p>where:</p>
<blockquote>
<div><p>-<span class="math notranslate nohighlight">\(w_a \cdot w_b\)</span> denotes the weight vectors</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>first_network</strong> – Network or list of layers.</p></li>
<li><p><strong>second_network</strong> – Network or list of layers.</p></li>
<li><p><strong>use_align</strong> – Boolean indicating whether to align the networks.</p></li>
<li><p><strong>cost_distance</strong> – String or function for pairwise computation of the cost matrix.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Array of pairwise cosine similarity for each layer.</p>
</dd>
</dl>
<p>Author: Youssouph Faye.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.distance_network.deep_relative_trust">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.distance_network.</span></span><span class="sig-name descname"><span class="pre">deep_relative_trust</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">first_network</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">second_network</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_align</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cost_distance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_drt_product</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="reference internal" href="_modules/deeplearningtools/helpers/distance_network.html#deep_relative_trust"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.distance_network.deep_relative_trust" title="Permalink to this definition">#</a></dt>
<dd><p>Compute the deep relative trust between two networks or list of layers.</p>
<p>Referenced from the paper “Deep Relative Trust” (<a class="reference external" href="https://arxiv.org/abs/2002.03432">https://arxiv.org/abs/2002.03432</a>).</p>
<p>This criterion computes the absolute difference between the projected trust values for each weight pair from the two networks, and normalizes this sum by the product of the number of layers and the dimension of the layers.
The deep relative trust between two networks or list of layers can be computed using the following equation:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\left| \frac{{f(x) - \tilde{f}(x)}}{{f(x)}} \right| \leq \left(1 + \frac{{|\Delta a|}}{{|a|}}\right) \left(1 + \frac{{|\Delta b|}}{{|b|}}\right) - 1\]</div>
</div>
<p>where:</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(f(x)\)</span> is the output of the first network or list of layers.</p></li>
<li><p><span class="math notranslate nohighlight">\(\tilde{f}(x)\)</span> is the output of the second network or list of layers.</p></li>
<li><p><span class="math notranslate nohighlight">\(\Delta a\)</span> represents the perturbation in the parameter <cite>a</cite>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\Delta b\)</span> represents the perturbation in the parameter <cite>b</cite>.</p></li>
<li><p><span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span> are the original parameters.</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>first_network</strong> – Network or list of layers.</p></li>
<li><p><strong>second_network</strong> – Network or list of layers.</p></li>
<li><p><strong>use_align</strong> – Boolean indicating whether to align the networks.</p></li>
<li><p><strong>cost_distance</strong> – String or function for pairwise computation of the cost matrix.</p></li>
<li><p><strong>return_drt_product</strong> – Boolean indicating whether to return the deep relative trust product.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Array of distances or deep relative trust product and distances.</p>
</dd>
</dl>
<p>Author: Youssouph Faye.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.distance_network.deep_relative_trust_similarity">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.distance_network.</span></span><span class="sig-name descname"><span class="pre">deep_relative_trust_similarity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">network_weights</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/distance_network.html#deep_relative_trust_similarity"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.distance_network.deep_relative_trust_similarity" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.distance_network.euclidean_norm">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.distance_network.</span></span><span class="sig-name descname"><span class="pre">euclidean_norm</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">first_network</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">second_network</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_align</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cost_distance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="reference internal" href="_modules/deeplearningtools/helpers/distance_network.html#euclidean_norm"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.distance_network.euclidean_norm" title="Permalink to this definition">#</a></dt>
<dd><p>Compute the Euclidean norm between two networks or list of layers.</p>
<p>The Euclidean norm can be calculated using the following equation:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[||w_b - w_a|| = \sqrt{\sum{(w_b - w_a)^2}}\]</div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>first_network</strong> – Network or list of layers.</p></li>
<li><p><strong>second_network</strong> – Network or list of layers.</p></li>
<li><p><strong>use_align</strong> – Boolean indicating whether to align the networks.</p></li>
<li><p><strong>cost_distance</strong> – String or function for pairwise computation of the cost matrix.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Array of Euclidean norm for each layer.</p>
</dd>
</dl>
<p>Author: Youssouph Faye.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.distance_network.flatten">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.distance_network.</span></span><span class="sig-name descname"><span class="pre">flatten</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="reference internal" href="_modules/deeplearningtools/helpers/distance_network.html#flatten"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.distance_network.flatten" title="Permalink to this definition">#</a></dt>
<dd><p>Flatten a list of weights arrays into a single 1D array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>weights</strong> – List of weights arrays.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Flattened array of weights.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.distance_network.l1">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.distance_network.</span></span><span class="sig-name descname"><span class="pre">l1</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">w_a</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">w_b</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="reference internal" href="_modules/deeplearningtools/helpers/distance_network.html#l1"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.distance_network.l1" title="Permalink to this definition">#</a></dt>
<dd><p>Calculate the L1 distance between two arrays or vectors.</p>
<p>The L1 distance, also known as the Manhattan distance or taxicab distance, between two arrays (or vectors) is a measure of the absolute difference between 
the corresponding elements of the arrays.
Mathematically, the L1 distance between two arrays, x and y, of equal size, can be calculated as follows:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[L1_{distance} = \sum_{i=1}^{n} |x_i - y_i|\]</div>
</div>
<p>where:</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x_i\)</span> and <span class="math notranslate nohighlight">\(y_i\)</span> are the corresponding elements of arrays x and y,</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>np.ndarray</em>) – The first array.</p></li>
<li><p><strong>y</strong> (<em>np.ndarray</em>) – The second array.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The L1 distance.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.distance_network.l2">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.distance_network.</span></span><span class="sig-name descname"><span class="pre">l2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">w_a</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">w_b</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="reference internal" href="_modules/deeplearningtools/helpers/distance_network.html#l2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.distance_network.l2" title="Permalink to this definition">#</a></dt>
<dd><p>Calculate the L2 distance between two arrays or vectors.</p>
<p>The L2 distance, also known as the Euclidean distance, between two arrays (or vectors) is a measure of the distance between these two points in Euclidean space. 
Mathematically, the distance L2 between two arrays, x and y, of equal size, can be calculated as follows:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[L2_{distance} = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}\]</div>
</div>
<p>where:</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x_i\)</span> and <span class="math notranslate nohighlight">\(y_i\)</span> are the corresponding elements of arrays x and y,</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>np.ndarray</em>) – The first array.</p></li>
<li><p><strong>y</strong> (<em>np.ndarray</em>) – The second array.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The L2 distance.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.distance_network.percentage_different_signs_gradients">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.distance_network.</span></span><span class="sig-name descname"><span class="pre">percentage_different_signs_gradients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">first_network</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">second_network</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_align</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cost_distance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="reference internal" href="_modules/deeplearningtools/helpers/distance_network.html#percentage_different_signs_gradients"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.distance_network.percentage_different_signs_gradients" title="Permalink to this definition">#</a></dt>
<dd><p>Compute the amount or percentage of weights or gradients that go in the same direction.
The higher the percentage, the greater the distance between two layers.
Referenced from the paper “CMFL: Mitigating Communication Overhead for Federated Learning” (<a class="reference external" href="https://home.cse.ust.hk/~weiwa/papers/cmfl-icdcs19.pdf">https://home.cse.ust.hk/~weiwa/papers/cmfl-icdcs19.pdf</a>).</p>
<p>The percentage of weights or gradients that go in the same direction can be computed using the following equation:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[e(u,\overline{u}) = \frac{{1}}{{N}} \sum_{j=1}^{N} I(sign(u_{j}) = sign(\overline{u}_{j}))\]</div>
</div>
<p>where:</p>
<blockquote>
<div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(u=&lt;u_1, u_2, ..., u_N&gt;\)</span> is the local update,</p></li>
<li><p><span class="math notranslate nohighlight">\(N\)</span> is number of model parameters,</p></li>
<li><p><span class="math notranslate nohighlight">\(I\text{{sign}}(u_{j} = \overline{u}_{j})=1\)</span> if <span class="math notranslate nohighlight">\(u_j\)</span> and <span class="math notranslate nohighlight">\(\overline{u}_{j}\)</span> are the same sign, and <span class="math notranslate nohighlight">\(0\)</span> otherwise.</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>first_network</strong> – Network or list of layers.</p></li>
<li><p><strong>second_network</strong> – Network or list of layers.</p></li>
<li><p><strong>use_align</strong> – Boolean indicating whether to align the networks.</p></li>
<li><p><strong>cost_distance</strong> – String or function for pairwise computation of the cost matrix.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Array of pairwise percentage layer.</p>
</dd>
</dl>
<p>Author: Youssouph Faye.</p>
</dd></dl>

</section>
<section id="module-deeplearningtools.helpers.federated">
<span id="deeplearningtools-helpers-federated-module"></span><h2>deeplearningtools.helpers.federated module<a class="headerlink" href="#module-deeplearningtools.helpers.federated" title="Permalink to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="deeplearningtools.helpers.federated.FlClient">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.federated.</span></span><span class="sig-name descname"><span class="pre">FlClient</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cid</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">settings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_iterations_per_epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_iterations_per_epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">workers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_writer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_dir</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/federated.html#FlClient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.federated.FlClient" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">NumPyClient</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.federated.FlClient.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/federated.html#FlClient.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.federated.FlClient.evaluate" title="Permalink to this definition">#</a></dt>
<dd><p>Evaluate the client model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parameters</strong> – Model parameters.</p></li>
<li><p><strong>config</strong> – Configuration dictionary.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple containing loss, number of validation samples, and a dictionary with accuracy.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.federated.FlClient.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/federated.html#FlClient.fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.federated.FlClient.fit" title="Permalink to this definition">#</a></dt>
<dd><p>Fit the client model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parameters</strong> – Model parameters.</p></li>
<li><p><strong>config</strong> – Configuration dictionary.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple containing updated model parameters, number of training samples, and a dictionary of log metrics.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.federated.FlClient.get_parameters">
<span class="sig-name descname"><span class="pre">get_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/federated.html#FlClient.get_parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.federated.FlClient.get_parameters" title="Permalink to this definition">#</a></dt>
<dd><p>Get the client model parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Model parameters.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deeplearningtools.helpers.federated.FlowerClient_">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.federated.</span></span><span class="sig-name descname"><span class="pre">FlowerClient_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_val</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/federated.html#FlowerClient_"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.federated.FlowerClient_" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">NumPyClient</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.federated.FlowerClient_.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/federated.html#FlowerClient_.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.federated.FlowerClient_.evaluate" title="Permalink to this definition">#</a></dt>
<dd><p>Evaluate the FL client model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parameters</strong> – Model parameters.</p></li>
<li><p><strong>config</strong> – Configuration dictionary.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple containing loss, number of validation samples, and a dictionary with accuracy.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.federated.FlowerClient_.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/federated.html#FlowerClient_.fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.federated.FlowerClient_.fit" title="Permalink to this definition">#</a></dt>
<dd><p>Fit the FL client model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parameters</strong> – Model parameters.</p></li>
<li><p><strong>config</strong> – Configuration dictionary.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple containing updated model parameters, number of training samples, ‘and an empty dictionary’. TODO utility of this empty dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.federated.FlowerClient_.get_parameters">
<span class="sig-name descname"><span class="pre">get_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/federated.html#FlowerClient_.get_parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.federated.FlowerClient_.get_parameters" title="Permalink to this definition">#</a></dt>
<dd><p>Get the FL client model parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>config</strong> – Configuration dictionary.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Model parameters.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-deeplearningtools.helpers.federated_utils.flclient">
<span id="deeplearningtools-helpers-federated-utils-flclient-module"></span><h2>deeplearningtools.helpers.federated_utils.flclient module<a class="headerlink" href="#module-deeplearningtools.helpers.federated_utils.flclient" title="Permalink to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="deeplearningtools.helpers.federated_utils.flclient.FlClient">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.federated_utils.flclient.</span></span><span class="sig-name descname"><span class="pre">FlClient</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">settings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_iterations_per_epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_iterations_per_epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">workers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_writer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">monitored_metric_initial_threshold</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/federated_utils/flclient.html#FlClient"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.federated_utils.flclient.FlClient" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">NumPyClient</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.federated_utils.flclient.FlClient.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/federated_utils/flclient.html#FlClient.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.federated_utils.flclient.FlClient.evaluate" title="Permalink to this definition">#</a></dt>
<dd><p>Evaluate the client model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parameters</strong> – Model parameters.</p></li>
<li><p><strong>config</strong> – Configuration dictionary.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple containing loss, number of validation samples, and a dictionary with accuracy.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.federated_utils.flclient.FlClient.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/federated_utils/flclient.html#FlClient.fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.federated_utils.flclient.FlClient.fit" title="Permalink to this definition">#</a></dt>
<dd><p>Fit the client model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parameters</strong> – Model parameters.</p></li>
<li><p><strong>config</strong> – Configuration dictionary.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple containing updated model parameters, number of training samples, and a dictionary of log metrics.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.federated_utils.flclient.FlClient.get_client_config_filename">
<span class="sig-name descname"><span class="pre">get_client_config_filename</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/federated_utils/flclient.html#FlClient.get_client_config_filename"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.federated_utils.flclient.FlClient.get_client_config_filename" title="Permalink to this definition">#</a></dt>
<dd><p>Just a helper to ensure consistent warm restart config file naming.</p>
<p>Returns a standardized config name.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Standardized config name.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.federated_utils.flclient.FlClient.get_parameters">
<span class="sig-name descname"><span class="pre">get_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/federated_utils/flclient.html#FlClient.get_parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.federated_utils.flclient.FlClient.get_parameters" title="Permalink to this definition">#</a></dt>
<dd><p>Get the client model parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Model parameters.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.federated_utils.flclient.FlClient.load_restart_config">
<span class="sig-name descname"><span class="pre">load_restart_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/federated_utils/flclient.html#FlClient.load_restart_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.federated_utils.flclient.FlClient.load_restart_config" title="Permalink to this definition">#</a></dt>
<dd><p>Loads a config file (if it exists) to recover last states, enabling warm restart.</p>
<p>This function loads all necessary data, including the last best monitored value, epoch index, etc.,
in order to better track the client model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>None</strong> – </p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Nothing</p>
</dd>
</dl>
<p>Updates some instance variables.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.federated_utils.flclient.FlClient.write_restart_config">
<span class="sig-name descname"><span class="pre">write_restart_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">monitored_loss_val</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/federated_utils/flclient.html#FlClient.write_restart_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.federated_utils.flclient.FlClient.write_restart_config" title="Permalink to this definition">#</a></dt>
<dd><p>Writes a config file (after each client.fit call) to save last states, enabling warm restart.</p>
<p>This function saves all necessary data, including the last best monitored value, epoch index, etc.,
in order to better track the client model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>monitored_loss_val</strong> (<em>float</em>) – The model’s monitored metric.</p>
</dd>
</dl>
<p>Writes a configuration file named ‘lastinfo_clientXXX.ini’ in the current working directory.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deeplearningtools.helpers.federated_utils.flclient.FlowerClient_">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.federated_utils.flclient.</span></span><span class="sig-name descname"><span class="pre">FlowerClient_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_val</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/federated_utils/flclient.html#FlowerClient_"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.federated_utils.flclient.FlowerClient_" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">NumPyClient</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.federated_utils.flclient.FlowerClient_.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/federated_utils/flclient.html#FlowerClient_.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.federated_utils.flclient.FlowerClient_.evaluate" title="Permalink to this definition">#</a></dt>
<dd><p>Evaluate the FL client model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parameters</strong> – Model parameters.</p></li>
<li><p><strong>config</strong> – Configuration dictionary.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple containing loss, number of validation samples, and a dictionary with accuracy.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.federated_utils.flclient.FlowerClient_.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/federated_utils/flclient.html#FlowerClient_.fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.federated_utils.flclient.FlowerClient_.fit" title="Permalink to this definition">#</a></dt>
<dd><p>Fit the FL client model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parameters</strong> – Model parameters.</p></li>
<li><p><strong>config</strong> – Configuration dictionary.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Tuple containing updated model parameters, number of training samples, ‘and an empty dictionary’. TODO utility of this empty dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.federated_utils.flclient.FlowerClient_.get_parameters">
<span class="sig-name descname"><span class="pre">get_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/federated_utils/flclient.html#FlowerClient_.get_parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.federated_utils.flclient.FlowerClient_.get_parameters" title="Permalink to this definition">#</a></dt>
<dd><p>Get the FL client model parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>config</strong> – Configuration dictionary.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Model parameters.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-deeplearningtools.helpers.file_io">
<span id="deeplearningtools-helpers-file-io-module"></span><h2>deeplearningtools.helpers.file_io module<a class="headerlink" href="#module-deeplearningtools.helpers.file_io" title="Permalink to this heading">#</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.file_io.count_lines">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.file_io.</span></span><span class="sig-name descname"><span class="pre">count_lines</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_header</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/file_io.html#count_lines"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.file_io.count_lines" title="Permalink to this definition">#</a></dt>
<dd><p>Count the number of lines in files that match a specified path.</p>
<p>Given a file path pattern, this function counts the total number of lines across all files
that match the specified path. It also provides an option to skip a certain number of lines
from the beginning of each file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em>) – The file path pattern to match.</p></li>
<li><p><strong>skip_header</strong> (<em>int</em>) – The number of lines to skip from the beginning of each file.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The total number of lines across all files.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.file_io.extractFilenames">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.file_io.</span></span><span class="sig-name descname"><span class="pre">extractFilenames</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">root_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_extension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'*.jpg'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raiseOnEmpty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/file_io.html#extractFilenames"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.file_io.extractFilenames" title="Permalink to this definition">#</a></dt>
<dd><p>Utility function to extract filenames based on a root directory and file extension.</p>
<p>Given a root directory and file extension, this function walks through the directory tree
to create a list of files that match the specified extension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root_dir</strong> (<em>str</em>) – The root folder from which files should be searched.</p></li>
<li><p><strong>file_extension</strong> (<em>str</em>) – The extension of the files to search for. Defaults to “.jpg”.</p></li>
<li><p><strong>raiseOnEmpty</strong> (<em>bool</em>) – A boolean flag indicating whether an exception should be raised if no file is found. Defaults to True.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A sorted list of filenames.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list[str]</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>ValueError</strong> – If no files are found and <cite>raiseOnEmpty</cite> is set to True.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-deeplearningtools.helpers.kafka_io">
<span id="deeplearningtools-helpers-kafka-io-module"></span><h2>deeplearningtools.helpers.kafka_io module<a class="headerlink" href="#module-deeplearningtools.helpers.kafka_io" title="Permalink to this heading">#</a></h2>
<p>This module makes use of the tensor serialization/parsing helpers proposed in tensor_msg_io.py.</p>
<p>Usage:</p>
<ul class="simple">
<li><p>Install and configure Kafka.</p></li>
<li><p>Start ZooKeeper and Kafka.</p></li>
<li><p>Create a topic named ‘demo-pics’.</p></li>
<li><p>Check topic behaviors.</p></li>
<li><p>Delete the ‘demo-pics’ topic to free up disk space.</p></li>
<li><p>List all available topics on a server.</p></li>
<li><p>Get topic details.</p></li>
</ul>
<p>Example commands:</p>
<p># tested with Kafka install and config:</p>
<p>wget  <a class="reference external" href="https://downloads.apache.org/kafka/2.7.1/kafka_2.13-2.7.1.tgz">https://downloads.apache.org/kafka/2.7.1/kafka_2.13-2.7.1.tgz</a></p>
<p>tar -xzf kafka_2.13-2.7.1.tgz</p>
<p># Start ZooKeeper and Kafka</p>
<p>./kafka_2.13-2.7.1/bin/zookeeper-server-start.sh -daemon ./kafka_2.13-2.7.1/config/zookeeper.properties</p>
<p>./kafka_2.13-2.7.1/bin/kafka-server-start.sh -daemon ./kafka_2.13-2.7.1/config/server.properties</p>
<p>echo “Waiting for 10 secs until Kafka and ZooKeeper services are up and running”</p>
<p>sleep 10</p>
<p># Create the ‘demo-pics’ topic</p>
<p>./kafka_2.13-2.7.1/bin/kafka-topics.sh –create –bootstrap-server 127.0.0.1:9092 –replication-factor 1 –partitions 1 –topic demo-pics</p>
<p># Check topic behaviors</p>
<p>./kafka_2.13-2.7.1/bin/kafka-topics.sh –describe –bootstrap-server 127.0.0.1:9092 –topic demo-pics</p>
<p># Delete the ‘demo-pics’ topic to free up disk space</p>
<p>./kafka_2.13-2.7.1/bin/kafka-topics.sh  –bootstrap-server 127.0.0.1:9092 –delete –topic demo-pics</p>
<p># List all available topics on a server</p>
<p>./kafka_2.13-2.7.1/bin/kafka-topics.sh  –list –bootstrap-server 127.0.0.1:9092</p>
<p># Get topic details</p>
<p>./kafka_2.13-2.7.1/bin/kafka-topics.sh  –bootstrap-server=localhost:9092 –describe –topic demo-pics</p>
<dl class="py class">
<dt class="sig sig-object py" id="deeplearningtools.helpers.kafka_io.KafkaIO">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.kafka_io.</span></span><span class="sig-name descname"><span class="pre">KafkaIO</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">topic_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">element_spec</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bootstrap_servers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['localhost:9092']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">flush_every</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/kafka_io.html#KafkaIO"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.kafka_io.KafkaIO" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.kafka_io.KafkaIO.kafka_dataset_consumer_tf_basic">
<span class="sig-name descname"><span class="pre">kafka_dataset_consumer_tf_basic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">IODataset</span></span></span><a class="reference internal" href="_modules/deeplearningtools/helpers/kafka_io.html#KafkaIO.kafka_dataset_consumer_tf_basic"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.kafka_io.KafkaIO.kafka_dataset_consumer_tf_basic" title="Permalink to this definition">#</a></dt>
<dd><p>Consume TensorFlow tensor sample pairs (tensor, label) from a Kafka topic and return an IODataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch_size</strong> (<em>int</em>) – The batch size.</p></li>
<li><p><strong>shuffle</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to shuffle the dataset. Defaults to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The IODataset containing the consumed data.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tfio.IODataset</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.kafka_io.KafkaIO.kafka_dataset_consumer_tf_custom">
<span class="sig-name descname"><span class="pre">kafka_dataset_consumer_tf_custom</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">IODataset</span></span></span><a class="reference internal" href="_modules/deeplearningtools/helpers/kafka_io.html#KafkaIO.kafka_dataset_consumer_tf_custom"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.kafka_io.KafkaIO.kafka_dataset_consumer_tf_custom" title="Permalink to this definition">#</a></dt>
<dd><p>Consume TensorFlow tensor sample pairs (tensor, label) from a Kafka topic and return an IODataset with custom features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>features</strong> (<em>list</em>) – The features to decode.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – The batch size.</p></li>
<li><p><strong>shuffle</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to shuffle the dataset. Defaults to False.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The IODataset containing the consumed data.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tfio.IODataset</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.kafka_io.KafkaIO.kafka_dataset_incremental_consumer_tf">
<span class="sig-name descname"><span class="pre">kafka_dataset_incremental_consumer_tf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">IODataset</span></span></span><a class="reference internal" href="_modules/deeplearningtools/helpers/kafka_io.html#KafkaIO.kafka_dataset_incremental_consumer_tf"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.kafka_io.KafkaIO.kafka_dataset_incremental_consumer_tf" title="Permalink to this definition">#</a></dt>
<dd><p>Create an incremental consumer for streaming datasets from Kafka using TensorFlow IODataset.</p>
<p>Note: This feature is not yet implemented.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>batch_size (int): The batch size for the dataset.
shuffle (bool): Whether to shuffle the dataset.</p>
</dd>
<dt>Returns:</dt><dd><p>tfio.IODataset: The incremental consumer dataset.</p>
</dd>
<dt>Raises:</dt><dd><p>NotImplementedError: Streaming datasets are not yet implemented.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.kafka_io.KafkaIO.kafka_producer_tf">
<span class="sig-name descname"><span class="pre">kafka_producer_tf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">items</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/deeplearningtools/helpers/kafka_io.html#KafkaIO.kafka_producer_tf"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.kafka_io.KafkaIO.kafka_producer_tf" title="Permalink to this definition">#</a></dt>
<dd><p>Publish TensorFlow tensor sample pairs (tensor, label) in the form of tensorflow.Examples from an iterable (list of tensor tuples, or a dataset) or something similar.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>items</strong> (<em>tf.Tensor</em>) – The TensorFlow tensor sample pairs to publish.</p></li>
<li><p><strong>log</strong> (<em>str</em><em>, </em><em>optional</em>) – The path to the log file. Defaults to None.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.kafka_io.error_callback">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.kafka_io.</span></span><span class="sig-name descname"><span class="pre">error_callback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">exc</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/kafka_io.html#error_callback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.kafka_io.error_callback" title="Permalink to this definition">#</a></dt>
<dd><p>Error callback function for handling exceptions during data sending to Kafka.</p>
<p>This function raises an Exception with the error message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>exc</strong> (<em>Exception</em>) – The exception raised during data sending.</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>Exception</strong> – Raises an Exception with the error message.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-deeplearningtools.helpers.loss">
<span id="deeplearningtools-helpers-loss-module"></span><h2>deeplearningtools.helpers.loss module<a class="headerlink" href="#module-deeplearningtools.helpers.loss" title="Permalink to this heading">#</a></h2>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Many loss functions need to be tested! Please check and compare with the original papers!</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Maybe have a look here: <a class="reference external" href="https://niftynet.readthedocs.io/en/dev/niftynet.layer.loss_segmentation.html">https://niftynet.readthedocs.io/en/dev/niftynet.layer.loss_segmentation.html</a></p>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.Regularizer_L1L2Ortho">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">Regularizer_L1L2Ortho</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">l1</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">l2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ortho</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ortho_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'soft'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_filters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#Regularizer_L1L2Ortho"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.Regularizer_L1L2Ortho" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>A regularizer that combine multiple ones (testing)</p>
<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.Regularizer_L1L2Ortho.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#Regularizer_L1L2Ortho.get_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.Regularizer_L1L2Ortho.get_config" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.Regularizer_None">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">Regularizer_None</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#Regularizer_None"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.Regularizer_None" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Custom regularizer that applies no regularization.</p>
<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.Regularizer_None.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#Regularizer_None.get_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.Regularizer_None.get_config" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.Regularizer_Spectral_Restricted_Isometry">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">Regularizer_Spectral_Restricted_Isometry</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">l</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_filters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#Regularizer_Spectral_Restricted_Isometry"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.Regularizer_Spectral_Restricted_Isometry" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.Regularizer_Spectral_Restricted_Isometry.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#Regularizer_Spectral_Restricted_Isometry.get_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.Regularizer_Spectral_Restricted_Isometry.get_config" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.Regularizer_soft_orthogonality">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">Regularizer_soft_orthogonality</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">l</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#Regularizer_soft_orthogonality"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.Regularizer_soft_orthogonality" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Soft orthogonalization regularizer.</p>
<p>This regularizer encourages the weight matrix of a layer to have a Gram matrix close to the identity matrix, promoting orthogonality among the weights.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>l</strong> – Regularization factor.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.Regularizer_soft_orthogonality.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#Regularizer_soft_orthogonality.get_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.Regularizer_soft_orthogonality.get_config" title="Permalink to this definition">#</a></dt>
<dd><p>Get the configuration of the regularizer.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.UncorrelatedFeaturesConstraint">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">UncorrelatedFeaturesConstraint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">encoding_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weightage</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#UncorrelatedFeaturesConstraint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.UncorrelatedFeaturesConstraint" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Constraint</span></code></p>
<p>Uncorrelated Features Constraint.</p>
<p>This constraint encourages the features of a layer to be uncorrelated by penalizing the covariance matrix deviation from the identity matrix.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>encoding_dim</strong> – The dimension of the encoded features.</p></li>
<li><p><strong>weightage</strong> – The weightage of the constraint penalty.</p></li>
</ul>
</dd>
</dl>
<p>Usage:
<code class="docutils literal notranslate"><span class="pre">`python</span>
<span class="pre">constraint</span> <span class="pre">=</span> <span class="pre">UncorrelatedFeaturesConstraint(encoding_dim,</span> <span class="pre">weightage=1.0)</span>
<span class="pre">`</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.UncorrelatedFeaturesConstraint.get_covariance">
<span class="sig-name descname"><span class="pre">get_covariance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#UncorrelatedFeaturesConstraint.get_covariance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.UncorrelatedFeaturesConstraint.get_covariance" title="Permalink to this definition">#</a></dt>
<dd><p>Calculate the covariance matrix of the input tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> – The input tensor.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The covariance matrix.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.UncorrelatedFeaturesConstraint.uncorrelated_feature">
<span class="sig-name descname"><span class="pre">uncorrelated_feature</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#UncorrelatedFeaturesConstraint.uncorrelated_feature"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.UncorrelatedFeaturesConstraint.uncorrelated_feature" title="Permalink to this definition">#</a></dt>
<dd><p>Compute the uncorrelated feature penalty.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> – The input tensor.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The penalty value.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.class_weights">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">class_weights</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples_per_class</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#class_weights"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.class_weights" title="Permalink to this definition">#</a></dt>
<dd><p>Compute class weights used to balance per-class loss during optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>samples_per_class</strong> (<em>numpy.ndarray</em>) – A numpy array containing the count of samples for each class (1D vector of length equal to the number of classes).</p></li>
<li><p><strong>beta</strong> (<em>float</em><em>, </em><em>optional</em>) – The beta value used in the computation. If not provided, it is calculated as (N-1)/N, where N is the total number of samples.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Class weights to be applied for each class loss.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>numpy.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.discrepancy_slice_wasserstein">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">discrepancy_slice_wasserstein</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p2</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#discrepancy_slice_wasserstein"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.discrepancy_slice_wasserstein" title="Permalink to this definition">#</a></dt>
<dd><p>Calculate the slice Wasserstein discrepancy between two distributions.</p>
<p>This function computes the slice Wasserstein discrepancy between two distributions <cite>p1</cite> and <cite>p2</cite> using random projections.</p>
<p>Reference: <a class="reference external" href="https://github.com/apple/ml-cvpr2019-swd">https://github.com/apple/ml-cvpr2019-swd</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p1</strong> – The first distribution tensor.</p></li>
<li><p><strong>p2</strong> – The second distribution tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The slice Wasserstein discrepancy.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.exponentialLogLoss">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">exponentialLogLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'loss'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#exponentialLogLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.exponentialLogLoss" title="Permalink to this definition">#</a></dt>
<dd><p>Apply a power law on the input loss function.</p>
<p>Reference: <a class="reference external" href="https://arxiv.org/pdf/1809.00076.pdf">https://arxiv.org/pdf/1809.00076.pdf</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>loss</strong> – A tensor of (preliminary weighted) metrics in the range [0,1].</p></li>
<li><p><strong>gamma</strong> – The exponent value for the power law.</p></li>
<li><p><strong>name</strong> – The name of the loss tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The average of (-log(loss))^gamma.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.focal_loss_softmax">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">focal_loss_softmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_class_sample_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_class_global_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_class_probs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'loss'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#focal_loss_softmax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.focal_loss_softmax" title="Permalink to this definition">#</a></dt>
<dd><p>Focal loss, a cross entropy like loss that favors hard examples
such that imbalanced data can be handled more easily
original work: <a class="reference external" href="https://arxiv.org/abs/1708.02002">https://arxiv.org/abs/1708.02002</a>
–&gt; also have a look at the proposed strategy on the last bias init.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>labels</strong> – A tensor of shape [batch_size,…] with class indexes (that will be one hot encoded internally).</p></li>
<li><p><strong>logits</strong> – A float32 tensor of shape [batch_size,…,num_classes].</p></li>
<li><p><strong>gamma</strong> – A scalar for focal loss gamma hyper-parameter.</p></li>
<li><p><strong>weight_class_sample_prob</strong> – If True, per-sample class loss is weighted by the related class sample probability.</p></li>
<li><p><strong>weight_class_global_prob</strong> – If True, weight the loss with respect to the true class probabilities in the training dataset.</p></li>
<li><p><strong>train_class_probs</strong> – A numpy array of class weights.</p></li>
<li><p><strong>name</strong> – The name of the loss tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A scalar loss value</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.generateTheta">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">generateTheta</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">L</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">endim</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#generateTheta"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.generateTheta" title="Permalink to this definition">#</a></dt>
<dd><p>Generate L random samples from the unit (endim)-dimensional space.</p>
<p>This function generates L random samples from the unit (endim)-dimensional space.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>L</strong> – The number of samples to generate.</p></li>
<li><p><strong>endim</strong> – The dimension of the samples.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Generated random samples from the unit (endim)-dimensional space.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.generateZ_circle">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">generateZ_circle</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batchsize</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#generateZ_circle"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.generateZ_circle" title="Permalink to this definition">#</a></dt>
<dd><p>Generate samples from a circle distribution in a 2-dimensional space.</p>
<p>This function generates 2D samples from a circle distribution in a 2-dimensional space.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batchsize</strong> – The number of samples to generate.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Generated samples from the circle distribution.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.generateZ_ring">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">generateZ_ring</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batchsize</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#generateZ_ring"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.generateZ_ring" title="Permalink to this definition">#</a></dt>
<dd><p>Generate samples from a ring distribution in a 2-dimensional space.</p>
<p>This function generates 2D samples from a ring distribution in a 2-dimensional space.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batchsize</strong> – The number of samples to generate.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Generated samples from the ring distribution.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.get_IOgradient_norm_lipschitzPenalty">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">get_IOgradient_norm_lipschitzPenalty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_lipschitz</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#get_IOgradient_norm_lipschitzPenalty"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.get_IOgradient_norm_lipschitzPenalty" title="Permalink to this definition">#</a></dt>
<dd><p>Computes a loss gradient Lipschitz regularizer.</p>
<p>This function calculates the norm of the gradients of the outputs with respect to the inputs and penalizes deviations from the target Lipschitz constant.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – The input tensor.</p></li>
<li><p><strong>outputs</strong> – The output tensor.</p></li>
<li><p><strong>target_lipschitz</strong> – The target Lipschitz constant.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The mean squared difference between the slopes (norms of the gradients) and the target Lipschitz constant.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.get_batch_flat_tensors">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">get_batch_flat_tensors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logits</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#get_batch_flat_tensors"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.get_batch_flat_tensors" title="Permalink to this definition">#</a></dt>
<dd><p>Prepare logits and label batch samples in a per-sample flat shape.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>labels</strong> (<em>tf.Tensor</em>) – The integer values that will be one-hot encoded internally. Shape: [batchsize, …, 1].</p></li>
<li><p><strong>logits</strong> (<em>tf.Tensor</em>) – The predicted logits with shape [batchsize, …, classes].</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>y_true, the one-hot encoded labels with shape [batchsize, n, classes], where n is the dimension of the flattened samples.
y_pred, the flattened logits with shape [batchsize, n, classes].</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[tf.Tensor, tf.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.get_per_sample_class_weights">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">get_per_sample_class_weights</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#get_per_sample_class_weights"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.get_per_sample_class_weights" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the vector of class weights of a 3D [batch, n, labels] one-hot encoded labels tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>y_true</strong> (<em>tf.Tensor</em>) – A tensor of shape [batchsize, n, one-hot labels].</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor that contains class weights for each sample.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
<p>WARNING: Weights are normalized to sum to 1. When some classes are not present, the weights of other classes increase!</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.get_sample_class_probabilities">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">get_sample_class_probabilities</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">one_hot_labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#get_sample_class_probabilities"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.get_sample_class_probabilities" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the vector of class probabilities of a 3D [batch, n, labels] one-hot encoded labels tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>one_hot_labels</strong> (<em>tf.Tensor</em>) – A tensor of shape [batchsize, n, one-hot labels].</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor containing class probabilities for each sample.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.kl_loss">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">kl_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">z_mean</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logvar</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">id</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#kl_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.kl_loss" title="Permalink to this definition">#</a></dt>
<dd><p>Compute the KL divergence loss between two distributions.</p>
<p>This function computes the KL divergence loss between two distributions, an identifier ‘id’ is considered for visibility on Tensorboard 
with tf.name_scope(‘kl_Divergence_loss’).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z_mean</strong> – The mean of the distribution.</p></li>
<li><p><strong>logvar</strong> – The log variance of the distribution.</p></li>
<li><p><strong>id</strong> – An identifier for visibility on TensorBoard.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The computed KL divergence loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.multi_loss">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">multi_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lossesList</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#multi_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.multi_loss" title="Permalink to this definition">#</a></dt>
<dd><p>Combine multiple losses into a single loss.</p>
<p>Reference: refactored from the original work of Y. Gal <a class="reference external" href="https://github.com/yaringal/multi-task-learning-example/blob/master/multi-task-learning-example.ipynb">https://github.com/yaringal/multi-task-learning-example/blob/master/multi-task-learning-example.ipynb</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lossesList</strong> – A list of dictionaries with keys (‘loss_value’, ‘name’) representing the losses to combine.</p></li>
<li><p><strong>logvars</strong> – A list of associated prediction logvars</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The combined loss as a single scalar value.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.multiclass_dice_loss_softmax">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">multiclass_dice_loss_softmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_class_sample_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_class_global_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_class_probs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'loss'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#multiclass_dice_loss_softmax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.multiclass_dice_loss_softmax" title="Permalink to this definition">#</a></dt>
<dd><p>Multiclass Sørensen-Dice index measure, softmax is applied internally on the y_preds.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>logits</strong> – The predicted logits with shape [batchsize, …, classes].</p></li>
<li><p><strong>labels</strong> – Integer values, will be one hot encoded internally [batchsize, …, 1].</p></li>
<li><p><strong>weight_class_sample_prob</strong> – Set True to weight the loss with respect to sample true class probabilities.</p></li>
<li><p><strong>weight_class_global_prob</strong> – Set True to weight the loss with respect to train dataset true class probabilities.</p></li>
<li><p><strong>train_class_probs</strong> – A numpy array of class weights.</p></li>
<li><p><strong>name</strong> – The name of the loss tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The average dice loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.multiclass_jaccard_loss_softmax">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">multiclass_jaccard_loss_softmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_class_sample_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_class_global_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_class_probs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'loss'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#multiclass_jaccard_loss_softmax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.multiclass_jaccard_loss_softmax" title="Permalink to this definition">#</a></dt>
<dd><p>Multiclass Jaccard loss measure, softmax is applied internally on the y_preds.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>logits</strong> – The predicted logits with shape [batchsize, …, classes].</p></li>
<li><p><strong>labels</strong> – Integer values, will be one hot encoded internally [batchsize, …, 1].</p></li>
<li><p><strong>weight_class_sample_prob</strong> – Set True to weight the loss with respect to sample true class probabilities.</p></li>
<li><p><strong>weight_class_global_prob</strong> – Set True to weight the loss with respect to train dataset true class probabilities.</p></li>
<li><p><strong>train_class_probs</strong> – A numpy array of class weights.</p></li>
<li><p><strong>name</strong> – The name of the loss tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The average Jaccard measures of shape [batchsize, classes].</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.multiclass_lovasz_loss_softmax">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">multiclass_lovasz_loss_softmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_class_sample_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_class_global_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_class_probs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'loss'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#multiclass_lovasz_loss_softmax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.multiclass_lovasz_loss_softmax" title="Permalink to this definition">#</a></dt>
<dd><p>Multiclass Jaccard loss measure, softmax is applied internally on the y_preds.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>logits</strong> – The predicted logits with shape [batchsize, …, classes].</p></li>
<li><p><strong>labels</strong> – Integer values, will be one hot encoded internally [batchsize, …, 1].</p></li>
<li><p><strong>weight_class_sample_prob</strong> – Set True to weight the loss with respect to sample true class probabilities.</p></li>
<li><p><strong>weight_class_global_prob</strong> – Set True to weight the loss with respect to train dataset true class probabilities.</p></li>
<li><p><strong>train_class_probs</strong> – A numpy array of class weights.</p></li>
<li><p><strong>name</strong> – The name of the loss tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The average Jaccard loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.multiclass_tversky_loss_softmax">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">multiclass_tversky_loss_softmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.7</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_class_sample_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_class_global_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_class_probs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">focal</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'loss'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#multiclass_tversky_loss_softmax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.multiclass_tversky_loss_softmax" title="Permalink to this definition">#</a></dt>
<dd><p>Multiclass Tversky loss measure, softmax is applied internally on the y_preds.</p>
<p>Reference: <a class="reference external" href="https://arxiv.org/pdf/1706.05721.pdf">https://arxiv.org/pdf/1706.05721.pdf</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>logits</strong> – The predicted logits with shape [batchsize, …, classes].</p></li>
<li><p><strong>labels</strong> – Integer values, will be one hot encoded internally [batchsize, …, 1].</p></li>
<li><p><strong>alpha</strong> – The weight of the false negatives penalty, (1-alpha) will be set to weigh false positives.</p></li>
<li><p><strong>weight_class_sample_prob</strong> – Set True to weight the loss with respect to sample true class probabilities.</p></li>
<li><p><strong>weight_class_global_prob</strong> – Set True to weight the loss with respect to train dataset true class probabilities.</p></li>
<li><p><strong>train_class_probs</strong> – A numpy array of class weights.</p></li>
<li><p><strong>focal</strong> – If value 0., activate the focal loss as presented in <a class="reference external" href="https://arxiv.org/pdf/1810.07842.pdf">https://arxiv.org/pdf/1810.07842.pdf</a>,
recommended value was 0.75.</p></li>
<li><p><strong>name</strong> – The name of the loss tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The average Tversky loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.preds_labels_preprocess_softmax_flatten">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">preds_labels_preprocess_softmax_flatten</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#preds_labels_preprocess_softmax_flatten"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.preds_labels_preprocess_softmax_flatten" title="Permalink to this definition">#</a></dt>
<dd><p>A tf.function to simplify the optimization graph:</p>
<ol class="arabic simple">
<li><p>Apply softmax to the input logits.</p></li>
<li><p>Flatten each sample of the input batch.</p></li>
</ol>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>logits</strong> (<em>tf.Tensor</em>) – The predicted logits with shape [batchsize, …, classes].</p></li>
<li><p><strong>labels</strong> (<em>tf.Tensor</em>) – The integer values that will be one-hot encoded internally. Shape: [batchsize, …, 1].</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>y_true, the flattened one-hot encoded labels with shape [batchsize, n, classes], where n is the dimension of the flattened samples.
y_pred, the flattened softmaxed logits with shape [batchsize, n, classes].</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[tf.Tensor, tf.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.reconstruction_loss_BCE">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">reconstruction_loss_BCE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reconstruction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pos_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#reconstruction_loss_BCE"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.reconstruction_loss_BCE" title="Permalink to this definition">#</a></dt>
<dd><p>Compute the binary cross-entropy (BCE) loss for reconstruction.</p>
<p>This function computes the BCE loss for the reconstruction of inputs and reconstruction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – The input tensor.</p></li>
<li><p><strong>reconstruction</strong> – The reconstructed tensor.</p></li>
<li><p><strong>pos_weight</strong> – The weight to assign to the positive class in the BCE loss. Default is 1.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The computed BCE loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.reconstruction_loss_BCE_soft">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">reconstruction_loss_BCE_soft</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reconstruction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">w</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.8</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#reconstruction_loss_BCE_soft"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.reconstruction_loss_BCE_soft" title="Permalink to this definition">#</a></dt>
<dd><p>Compute the binary cross-entropy (BCE) loss with soft labels for reconstruction.</p>
<p>This function computes the BCE loss with soft labels for the reconstruction of inputs and reconstruction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – The input tensor.</p></li>
<li><p><strong>reconstruction</strong> – The reconstructed tensor.</p></li>
<li><p><strong>w</strong> – The weight for balancing the loss between white and non-white pixels. Default is 0.8.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The computed BCE loss with soft labels.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.reconstruction_loss_L1">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">reconstruction_loss_L1</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reconstruction</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#reconstruction_loss_L1"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.reconstruction_loss_L1" title="Permalink to this definition">#</a></dt>
<dd><p>Compute the reconstruction L1 loss.</p>
<p>This function computes the reconstruction L1 loss (mean absolute error).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – The input tensor.</p></li>
<li><p><strong>reconstruction</strong> – The reconstructed tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The computed L1 loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.reconstruction_loss_MSE">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">reconstruction_loss_MSE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reconstruction</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#reconstruction_loss_MSE"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.reconstruction_loss_MSE" title="Permalink to this definition">#</a></dt>
<dd><p>Compute the mean squared error (MSE) loss for reconstruction.</p>
<p>This function computes the MSE loss for the reconstruction of inputs and reconstruction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – The input tensor.</p></li>
<li><p><strong>reconstruction</strong> – The reconstructed tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The computed MSE loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.slicedWasserteinLoss_single">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">slicedWasserteinLoss_single</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">code</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_z</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_points</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#slicedWasserteinLoss_single"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.slicedWasserteinLoss_single" title="Permalink to this definition">#</a></dt>
<dd><p>Calculate the Sliced Wasserstein loss for a single code.</p>
<p>This function computes the Sliced Wasserstein loss for a single code based on the given target z samples and sample points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>code</strong> – The code for which to calculate the loss.</p></li>
<li><p><strong>target_z</strong> – The target z samples.</p></li>
<li><p><strong>sample_points</strong> – The sample points for projection.</p></li>
<li><p><strong>batch_size</strong> – The batch size.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The Sliced Wasserstein loss for the single code.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.smooth_labels">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">smooth_labels</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">factor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#smooth_labels"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.smooth_labels" title="Permalink to this definition">#</a></dt>
<dd><p>Smooths the labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>labels</strong> (<em>tf.Tensor</em>) – The input labels to be smoothed.</p></li>
<li><p><strong>factor</strong> (<em>float</em>) – The smoothing factor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The smoothed labels.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.swae_loss">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">swae_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">code_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_z</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">L</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#swae_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.swae_loss" title="Permalink to this definition">#</a></dt>
<dd><p>Calculate the Sliced Wasserstein Autoencoder (AE) loss.</p>
<p>This function computes the Sliced Wasserstein Autoencoder (AE) loss based on the given AE codes and target z samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>code_list</strong> – A list of AE codes.</p></li>
<li><p><strong>target_z</strong> – The target z samples.</p></li>
<li><p><strong>batch_size</strong> – The batch size.</p></li>
<li><p><strong>L</strong> – The number of sample points to project on (default: 50).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The Sliced Wasserstein Autoencoder (AE) loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.tensor_gram_matrix">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">tensor_gram_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#tensor_gram_matrix"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.tensor_gram_matrix" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the Gram matrix of a given tensor matrix.</p>
<p>Note that the input tensor is reshaped to a 2D matrix, preserving the last dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>tensor</strong> – The input tensor.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The Gram matrix of the tensor.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.loss.weighted_xcrosspow_loss_softmax">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.loss.</span></span><span class="sig-name descname"><span class="pre">weighted_xcrosspow_loss_softmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_class_sample_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_class_global_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_class_probs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'loss'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/loss.html#weighted_xcrosspow_loss_softmax"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.loss.weighted_xcrosspow_loss_softmax" title="Permalink to this definition">#</a></dt>
<dd><p>A cross entropy loss with a power low, same idea as for focal loss but, limits oversupression of high scores
from <a class="reference external" href="https://arxiv.org/pdf/1809.00076.pdf">https://arxiv.org/pdf/1809.00076.pdf</a>
added specific weightings</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>labels</strong> – A tensor of shape [batch_size,…] with class indexes (that will be one hot encoded internally).</p></li>
<li><p><strong>logits</strong> – A float32 tensor of shape [batch_size,…,num_classes].</p></li>
<li><p><strong>gamma</strong> – The power value for the power law.</p></li>
<li><p><strong>weight_class_sample_prob</strong> – If True, per-sample class loss is weighted by the related class sample probability.</p></li>
<li><p><strong>weight_class_global_prob</strong> – If True, weight the loss with respect to the true class probabilities in the training dataset.</p></li>
<li><p><strong>train_class_probs</strong> – A numpy array of class weights.</p></li>
<li><p><strong>name</strong> – The name of the loss tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A cross entropy tensor of shape [batchsize, classes]</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-deeplearningtools.helpers.model_serving_tools">
<span id="deeplearningtools-helpers-model-serving-tools-module"></span><h2>deeplearningtools.helpers.model_serving_tools module<a class="headerlink" href="#module-deeplearningtools.helpers.model_serving_tools" title="Permalink to this heading">#</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model_serving_tools.WaitForServerReady">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.model_serving_tools.</span></span><span class="sig-name descname"><span class="pre">WaitForServerReady</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">usersettings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">host</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">port</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model_serving_tools.html#WaitForServerReady"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model_serving_tools.WaitForServerReady" title="Permalink to this definition">#</a></dt>
<dd><p>Waits for a server on the localhost to become ready.</p>
<p>Reference: inspired from <a class="reference external" href="https://github.com/tensorflow/serving/blob/master/tensorflow_serving/model_servers/tensorflow_model_server_test.py">https://github.com/tensorflow/serving/blob/master/tensorflow_serving/model_servers/tensorflow_model_server_test.py</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>usersettings</strong> – The user settings.</p></li>
<li><p><strong>host</strong> – The TensorFlow server address.</p></li>
<li><p><strong>port</strong> – The port address of the PredictionService.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>True if the server is ready, False on timeout.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model_serving_tools.decode_model_serving_answer">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.model_serving_tools.</span></span><span class="sig-name descname"><span class="pre">decode_model_serving_answer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">answer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_names</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model_serving_tools.html#decode_model_serving_answer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model_serving_tools.decode_model_serving_answer" title="Permalink to this definition">#</a></dt>
<dd><p>Classical decoding approach but still slow (numpy array creation from iterable is slow).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>answer</strong> – The model_server predict request response.</p></li>
<li><p><strong>output_names</strong> – The list of output names to be decoded.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The list of numpy arrays.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model_serving_tools.deserialize_srv_answer_uint8">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.model_serving_tools.</span></span><span class="sig-name descname"><span class="pre">deserialize_srv_answer_uint8</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">proto_single_output</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model_serving_tools.html#deserialize_srv_answer_uint8"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model_serving_tools.deserialize_srv_answer_uint8" title="Permalink to this definition">#</a></dt>
<dd><p>Deserialize a protobuf output into a tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>proto_single_output</strong> – A protobuf output supposed to be a serialized tensor of type tf.uint8.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The deserialized tensor.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model_serving_tools.deserialize_srv_answer_uint8_vfrombuffer">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.model_serving_tools.</span></span><span class="sig-name descname"><span class="pre">deserialize_srv_answer_uint8_vfrombuffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">msg_buffer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model_serving_tools.html#deserialize_srv_answer_uint8_vfrombuffer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model_serving_tools.deserialize_srv_answer_uint8_vfrombuffer" title="Permalink to this definition">#</a></dt>
<dd><p>Faster but less elegant method to deserialize a protobuf output into a tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>msg_buffer</strong> – The protobuf message buffer.</p></li>
<li><p><strong>shape</strong> – The shape of the tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The deserialized tensor.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model_serving_tools.generate_single_request">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.model_serving_tools.</span></span><span class="sig-name descname"><span class="pre">generate_single_request</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model_serving_tools.html#generate_single_request"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model_serving_tools.generate_single_request" title="Permalink to this definition">#</a></dt>
<dd><p>Build and send a single request to the server.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sample</strong> – A dictionary with keys as input tensor names and values as numpy arrays.</p></li>
<li><p><strong>model_name</strong> – The name of the model.</p></li>
<li><p><strong>debug</strong> – Whether to print debug information.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The predict request.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model_serving_tools.get_model_server_cfg">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.model_serving_tools.</span></span><span class="sig-name descname"><span class="pre">get_model_server_cfg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_dir</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model_serving_tools.html#get_model_server_cfg"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model_serving_tools.get_model_server_cfg" title="Permalink to this definition">#</a></dt>
<dd><p>Read model server configuration from the model_serving_setup.ini written in the target experiment folder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model_dir</strong> – Path to an experiment (trained model).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dictionary that describes the expected server configuration.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model_serving_tools.get_served_model_info">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.model_serving_tools.</span></span><span class="sig-name descname"><span class="pre">get_served_model_info</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">one_model_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expected_model_name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model_serving_tools.html#get_served_model_info"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model_serving_tools.get_served_model_info" title="Permalink to this definition">#</a></dt>
<dd><p>Basic function that checks served model behaviors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>one_model_path</strong> – The path to a servable model directory.</p></li>
<li><p><strong>expected_model_name</strong> – The model name that is expected to be found on the server.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Nothing for now.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model_serving_tools.setup_model_server_connexion">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.model_serving_tools.</span></span><span class="sig-name descname"><span class="pre">setup_model_server_connexion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">host</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">port</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grpc_max_message_length</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model_serving_tools.html#setup_model_server_connexion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model_serving_tools.setup_model_server_connexion" title="Permalink to this definition">#</a></dt>
<dd><p>Set up the connection to the model server for prediction.</p>
<p>Test scripts may help : <a class="reference external" href="https://github.com/tensorflow/serving/blob/master/tensorflow_serving/model_servers/tensorflow_model_server_test.py">https://github.com/tensorflow/serving/blob/master/tensorflow_serving/model_servers/tensorflow_model_server_test.py</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>host</strong> – The host address of the model server.</p></li>
<li><p><strong>port</strong> – The port number of the model server.</p></li>
<li><p><strong>grpc_max_message_length</strong> – Maximum message length for gRPC communication.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The prediction service stub for making predictions.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-deeplearningtools.helpers.model_tcn">
<span id="deeplearningtools-helpers-model-tcn-module"></span><h2>deeplearningtools.helpers.model_tcn module<a class="headerlink" href="#module-deeplearningtools.helpers.model_tcn" title="Permalink to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model_tcn.ResidualBlock">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.model_tcn.</span></span><span class="sig-name descname"><span class="pre">ResidualBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model_tcn.html#ResidualBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model_tcn.ResidualBlock" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Layer</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model_tcn.ResidualBlock.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model_tcn.html#ResidualBlock.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model_tcn.ResidualBlock.build" title="Permalink to this definition">#</a></dt>
<dd><p>Builds the ResidualBlock.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> – Shape of the input tensor.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model_tcn.ResidualBlock.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model_tcn.html#ResidualBlock.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model_tcn.ResidualBlock.call" title="Permalink to this definition">#</a></dt>
<dd><p>Executes the ResidualBlock.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – Input tensor.</p></li>
<li><p><strong>training</strong> – Boolean indicating whether the layer should be trained or not.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple where the first element is the residual model tensor, and the second is the skip connection tensor.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model_tcn.ResidualBlock.compute_output_shape">
<span class="sig-name descname"><span class="pre">compute_output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model_tcn.html#ResidualBlock.compute_output_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model_tcn.ResidualBlock.compute_output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Computes the output shape of the ResidualBlock.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> – Shape of the input tensor.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list containing two elements, both representing the output shape of the layer.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model_tcn.TCN">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.model_tcn.</span></span><span class="sig-name descname"><span class="pre">TCN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model_tcn.html#TCN"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model_tcn.TCN" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Layer</span></code></p>
<p>Creates a TCN layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>nb_filters</strong> – The number of filters to use in the convolutional layers. Can be a list.</p></li>
<li><p><strong>kernel_size</strong> – The size of the kernel to use in each convolutional layer.</p></li>
<li><p><strong>dilations</strong> – The list of the dilations. Example is: [1, 2, 4, 8, 16, 32, 64].</p></li>
<li><p><strong>nb_stacks</strong> – The number of stacks of residual blocks to use.</p></li>
<li><p><strong>padding</strong> – The padding to use in the convolutional layers, ‘causal’ or ‘same’.</p></li>
<li><p><strong>use_skip_connections</strong> – Boolean. If we want to add skip connections from input to each residual blocK.</p></li>
<li><p><strong>return_sequences</strong> – Boolean. Whether to return the last output in the output sequence, or the full sequence.</p></li>
<li><p><strong>activation</strong> – The activation used in the residual blocks o = Activation(x + F(x)).</p></li>
<li><p><strong>dropout_rate</strong> – Float between 0 and 1. Fraction of the input units to drop.</p></li>
<li><p><strong>kernel_initializer</strong> – Initializer for the kernel weights matrix (Conv1D).</p></li>
<li><p><strong>use_batch_norm</strong> – Whether to use batch normalization in the residual layers or not.</p></li>
<li><p><strong>kwargs</strong> – Any other arguments for configuring parent class Layer. For example “name=str”, Name of the model.
Use unique names when using multiple TCN.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A TCN layer.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model_tcn.TCN.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model_tcn.html#TCN.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model_tcn.TCN.build" title="Permalink to this definition">#</a></dt>
<dd><p>Builds the TCN layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> – Shape of the input tensor.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model_tcn.TCN.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model_tcn.html#TCN.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model_tcn.TCN.call" title="Permalink to this definition">#</a></dt>
<dd><p>Call the TCN model and define layers trainable.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – The input tensor.</p></li>
<li><p><strong>training</strong> – Boolean flag indicating whether the layer should be trained.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>TCN model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model_tcn.TCN.compute_output_shape">
<span class="sig-name descname"><span class="pre">compute_output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model_tcn.html#TCN.compute_output_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model_tcn.TCN.compute_output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Computes the output shape of the TCN layer.</p>
<p>Note: Overridden in case keras uses it somewhere… no idea. Just trying to avoid future errors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> – Shape of the input tensor.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list containing the output shape of the layer.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model_tcn.TCN.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model_tcn.html#TCN.get_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model_tcn.TCN.get_config" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the config of a the layer. This is used for saving and loading from a model</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>python dictionary with specs to rebuild layer</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model_tcn.TCN.receptive_field">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">receptive_field</span></span><a class="headerlink" href="#deeplearningtools.helpers.model_tcn.TCN.receptive_field" title="Permalink to this definition">#</a></dt>
<dd><p>Computes the receptive field of the TCN layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The receptive field size.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model_tcn.adjust_dilations">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.model_tcn.</span></span><span class="sig-name descname"><span class="pre">adjust_dilations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dilations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model_tcn.html#adjust_dilations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model_tcn.adjust_dilations" title="Permalink to this definition">#</a></dt>
<dd><p>Adjusts the dilations to ensure that all values in the list are powers of two.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>dilations</strong> – The list of dilations to adjust.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The adjusted list of dilations.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model_tcn.compiled_tcn">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.model_tcn.</span></span><span class="sig-name descname"><span class="pre">compiled_tcn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_feat</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_filters</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nb_stacks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_len</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_len</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'causal'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_skip_connections</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_sequences</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">regression</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'tcn'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_initializer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'he_normal'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'relu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">opt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'adam'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.002</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_batch_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_layer_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_weight_norm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Model</span></span></span><a class="reference internal" href="_modules/deeplearningtools/helpers/model_tcn.html#compiled_tcn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model_tcn.compiled_tcn" title="Permalink to this definition">#</a></dt>
<dd><p>Creates a compiled TCN model for a given task (i.e. regression or classification).
Classification uses a sparse categorical loss. Please input class ids and not one-hot encodings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_feat</strong> – The number of features of your input, i.e. the last dimension of: (batch_size, timesteps, input_dim).</p></li>
<li><p><strong>num_classes</strong> – The size of the final dense layer, how many classes we are predicting.</p></li>
<li><p><strong>nb_filters</strong> – The number of filters to use in the convolutional layers.</p></li>
<li><p><strong>kernel_size</strong> – The size of the kernel to use in each convolutional layer.</p></li>
<li><p><strong>dilations</strong> – The list of the dilations. Example is: [1, 2, 4, 8, 16, 32, 64].</p></li>
<li><p><strong>nb_stacks</strong> – The number of stacks of residual blocks to use.</p></li>
<li><p><strong>max_len</strong> – The maximum sequence length, use None if the sequence length is dynamic.</p></li>
<li><p><strong>output_len</strong> – The length of the output sequence.</p></li>
<li><p><strong>padding</strong> – The padding to use in the convolutional layers.</p></li>
<li><p><strong>use_skip_connections</strong> – Boolean. If we want to add skip connections from input to each residual block.</p></li>
<li><p><strong>return_sequences</strong> – Boolean. Whether to return the last output in the output sequence, or the full sequence.</p></li>
<li><p><strong>regression</strong> – Whether the output should be continuous or discrete.</p></li>
<li><p><strong>dropout_rate</strong> – Float between 0 and 1. Fraction of the input units to drop.</p></li>
<li><p><strong>name</strong> – Name of the model. Useful when having multiple TCN.</p></li>
<li><p><strong>kernel_initializer</strong> – Initializer for the kernel weights matrix (Conv1D).</p></li>
<li><p><strong>activation</strong> – The activation used in the residual blocks o = Activation(x + F(x)).</p></li>
<li><p><strong>opt</strong> – Optimizer name.</p></li>
<li><p><strong>lr</strong> – Learning rate.</p></li>
<li><p><strong>use_batch_norm</strong> – Whether to use batch normalization in the residual layers or not.</p></li>
<li><p><strong>use_layer_norm</strong> – Whether to use layer normalization in the residual layers or not.</p></li>
<li><p><strong>use_weight_norm</strong> – Whether to use weight normalization in the residual layers or not.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A compiled Keras TCN model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model_tcn.is_power_of_two">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.model_tcn.</span></span><span class="sig-name descname"><span class="pre">is_power_of_two</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model_tcn.html#is_power_of_two"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model_tcn.is_power_of_two" title="Permalink to this definition">#</a></dt>
<dd><p>Check if a number is a power of two.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>num</strong> – The number to check.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>True if the number is a power of two, False otherwise.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model_tcn.tcn_full_summary">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.model_tcn.</span></span><span class="sig-name descname"><span class="pre">tcn_full_summary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expand_residual_blocks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model_tcn.html#tcn_full_summary"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model_tcn.tcn_full_summary" title="Permalink to this definition">#</a></dt>
<dd><p>Prints the full summary of a TCN model, including the layers within ResidualBlocks if specified.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The TCN model.</p></li>
<li><p><strong>expand_residual_blocks</strong> – Boolean. If True, expands the ResidualBlocks to show the layers within them.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-deeplearningtools.helpers.model">
<span id="deeplearningtools-helpers-model-module"></span><h2>deeplearningtools.helpers.model module<a class="headerlink" href="#module-deeplearningtools.helpers.model" title="Permalink to this heading">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model.ConcreteDropout">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.model.</span></span><span class="sig-name descname"><span class="pre">ConcreteDropout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model.html#ConcreteDropout"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model.ConcreteDropout" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Wrapper</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model.ConcreteDropout.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model.html#ConcreteDropout.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model.ConcreteDropout.build" title="Permalink to this definition">#</a></dt>
<dd><p>Builds the ConcreteDropout layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>(</strong><strong>tuple</strong><strong>)</strong> (<em>input_shape</em>) – Shape of the input tensor.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model.ConcreteDropout.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model.html#ConcreteDropout.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model.ConcreteDropout.call" title="Permalink to this definition">#</a></dt>
<dd><p>Apply Concrete Dropout regularization to the input and execute the wrapped layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>inputs</strong> – Input tensor.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Result of executing the wrapped layer with Concrete Dropout regularization applied.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model.ConcreteDropout.compute_output_shape">
<span class="sig-name descname"><span class="pre">compute_output_shape</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model.html#ConcreteDropout.compute_output_shape"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model.ConcreteDropout.compute_output_shape" title="Permalink to this definition">#</a></dt>
<dd><p>Computes the output shape of the layer.</p>
<p>This method will cause the layer’s state to be built, if that has not
happened before. This requires that the layer will later be used with
inputs that match the input shape provided here.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>input_shape: Shape tuple (tuple of integers) or <cite>tf.TensorShape</cite>,</dt><dd><p>or structure of shape tuples / <cite>tf.TensorShape</cite> instances
(one per output tensor of the layer).
Shape tuples can include None for free dimensions,
instead of an integer.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p>A <cite>tf.TensorShape</cite> instance
or structure of <cite>tf.TensorShape</cite> instances.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model.ConcreteDropout.concrete_dropout">
<span class="sig-name descname"><span class="pre">concrete_dropout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model.html#ConcreteDropout.concrete_dropout"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model.ConcreteDropout.concrete_dropout" title="Permalink to this definition">#</a></dt>
<dd><p>Generate concrete dropout following a sigmoid distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> – Input.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Probability dropped out.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model.ReplicatedOrthogonalInitialize">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.model.</span></span><span class="sig-name descname"><span class="pre">ReplicatedOrthogonalInitialize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scale</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gain</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model.html#ReplicatedOrthogonalInitialize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model.ReplicatedOrthogonalInitialize" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Orthogonal</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model.ReplicatedOrthogonalInitialize.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model.html#ReplicatedOrthogonalInitialize.get_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model.ReplicatedOrthogonalInitialize.get_config" title="Permalink to this definition">#</a></dt>
<dd><p>Returns the initializer’s configuration as a JSON-serializable dict.</p>
<dl class="simple">
<dt>Returns:</dt><dd><p>A JSON-serializable Python dict.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model.SubpixelConv2D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.model.</span></span><span class="sig-name descname"><span class="pre">SubpixelConv2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">factor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model.html#SubpixelConv2D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model.SubpixelConv2D" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Subpixel convolution/pixelshuffling approach (<a class="reference external" href="https://arxiv.org/abs/1609.05158">https://arxiv.org/abs/1609.05158</a>)</p>
<p>Upscaling Tensor from (any, h, w, c) to (any, h*factor, w*factor, c)</p>
<dl class="py method">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model.SubpixelConv2D.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model.html#SubpixelConv2D.get_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model.SubpixelConv2D.get_config" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model.atrous_Spatial_pyramid_pooling">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.model.</span></span><span class="sig-name descname"><span class="pre">atrous_Spatial_pyramid_pooling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_features</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outing_nb_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">256</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[1,</span> <span class="pre">6,</span> <span class="pre">12,</span> <span class="pre">18]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_sizes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[1,</span> <span class="pre">3,</span> <span class="pre">3,</span> <span class="pre">3]</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model.html#atrous_Spatial_pyramid_pooling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model.atrous_Spatial_pyramid_pooling" title="Permalink to this definition">#</a></dt>
<dd><p>Applies atrous spatial pyramid pooling to the input features.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_features</strong> – Input features to apply atrous spatial pyramid pooling on.</p></li>
<li><p><strong>outing_nb_features</strong> – Number of output features. Default is 256.</p></li>
<li><p><strong>rates</strong> – List of dilation rates for the dilated convolutions. Default is [1, 6, 12, 18].</p></li>
<li><p><strong>kernel_sizes</strong> – List of kernel sizes for the dilated convolutions. Default is [1, 3, 3, 3].</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Features after applying atrous spatial pyramid pooling.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model.concrete_dropout">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.model.</span></span><span class="sig-name descname"><span class="pre">concrete_dropout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainable</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_regularizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_regularizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_min</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model.html#concrete_dropout"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model.concrete_dropout" title="Permalink to this definition">#</a></dt>
<dd><p>Applies concrete dropout regularization to the inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> (<em>tf.Tensor</em>) – The input tensor.</p></li>
<li><p><strong>layer</strong> (<em>tf.keras.layers.Layer</em>) – The layer to apply concrete dropout to.</p></li>
<li><p><strong>trainable</strong> (<em>bool</em>) – Whether the concrete dropout parameters are trainable (True) or fixed (False). Defaults to True.</p></li>
<li><p><strong>weight_regularizer</strong> (<em>float</em>) – The weight regularization strength. Defaults to 1e-6.</p></li>
<li><p><strong>dropout_regularizer</strong> (<em>float</em>) – The dropout regularization strength. Defaults to 1e-5.</p></li>
<li><p><strong>init_min</strong> (<em>float</em>) – The minimum value for initializing the dropout parameters. Defaults to 0.1.</p></li>
<li><p><strong>init_max</strong> (<em>float</em>) – The maximum value for initializing the dropout parameters. Defaults to 0.1.</p></li>
<li><p><strong>training</strong> – Whether the model is in training mode or not. Defaults to True.</p></li>
<li><p><strong>name</strong> (<em>str</em>) – Name of the concrete dropout layer. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The output tensor after applying concrete dropout.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model.load_model">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.model.</span></span><span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">custom_objects</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model.html#load_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model.load_model" title="Permalink to this definition">#</a></dt>
<dd><p>Load a saved Keras model from the given path.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em>) – The path to the saved model file.</p></li>
<li><p><strong>custom_objects</strong> (<em>dict</em><em>, </em><em>optional</em>) – Optional dictionary mapping names (strings) to custom classes or functions to be used during loading.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The loaded Keras model.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.keras.Model</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model.make_circle_cloud_dataset">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.model.</span></span><span class="sig-name descname"><span class="pre">make_circle_cloud_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">samples_number</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model.html#make_circle_cloud_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model.make_circle_cloud_dataset" title="Permalink to this definition">#</a></dt>
<dd><p>”
Create a circle dataset with unit average radius and gaussain noise dispersion</p>
<p>:param samples_number : The number of points to generate.
:return circle_samples: The (x,y) coordinates of the sampled points.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model.test_ReplicatedOrthogonalInitialize">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.model.</span></span><span class="sig-name descname"><span class="pre">test_ReplicatedOrthogonalInitialize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[3,</span> <span class="pre">3,</span> <span class="pre">16,</span> <span class="pre">32]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model.html#test_ReplicatedOrthogonalInitialize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model.test_ReplicatedOrthogonalInitialize" title="Permalink to this definition">#</a></dt>
<dd><p>Tests ReplicatedOrthogonalInitialize by initializing a tensor and displaying its representation using matplotlib.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> – Shape of the tensor. Default is [3, 3, 16, 32].</p></li>
<li><p><strong>scale</strong> – Scale factor for replication. Default is 2.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Normalized representation of the initialized tensor.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model.track_gradients">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.model.</span></span><span class="sig-name descname"><span class="pre">track_gradients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model.html#track_gradients"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model.track_gradients" title="Permalink to this definition">#</a></dt>
<dd><p>Helper function to use in the getOptimizer function to compute and gradients and log them into the Tensorboard</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>loss</strong> – the loss to be appled for gradients computation</p>
</dd>
<dt class="field-even">Return tvars<span class="colon">:</span></dt>
<dd class="field-even"><p>the trainable variables</p>
</dd>
<dt class="field-odd">Return raw_grads<span class="colon">:</span></dt>
<dd class="field-odd"><p>the raw gradient values</p>
</dd>
<dt class="field-even">Return gradient_norm<span class="colon">:</span></dt>
<dd class="field-even"><p>the gradient global norm</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.model.track_weights_change">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.model.</span></span><span class="sig-name descname"><span class="pre">track_weights_change</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">round</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/model.html#track_weights_change"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.model.track_weights_change" title="Permalink to this definition">#</a></dt>
<dd><p>Tracks the change in weights between two sets of weights and writes simple numeric values for later analysis in TensorBoard.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The model whose weights are being tracked.</p></li>
<li><p><strong>weights</strong> – The reference set of weights to compare with.</p></li>
<li><p><strong>round</strong> – The current training round or step.</p></li>
<li><p><strong>prefix</strong> – Optional prefix for the summary names.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-deeplearningtools.helpers.opencv_tools">
<span id="deeplearningtools-helpers-opencv-tools-module"></span><h2>deeplearningtools.helpers.opencv_tools module<a class="headerlink" href="#module-deeplearningtools.helpers.opencv_tools" title="Permalink to this heading">#</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.opencv_tools.add_text_overlay">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.opencv_tools.</span></span><span class="sig-name descname"><span class="pre">add_text_overlay</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">text</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pos</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">font_color</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(255,</span> <span class="pre">255,</span> <span class="pre">255)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bg_color</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0,</span> <span class="pre">0,</span> <span class="pre">0)</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/opencv_tools.html#add_text_overlay"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.opencv_tools.add_text_overlay" title="Permalink to this definition">#</a></dt>
<dd><p>Add a text overlay to an image.</p>
<p>This function adds a text overlay to the given image. It uses the OpenCV library to draw a rectangle as the background
for the text and then adds the text on top of it.</p>
<p>The text overlay is placed at the specified position (top-left corner) on the image. The scale parameter can be used
to adjust the size of the text. The font_color parameter determines the color of the text, and the bg_color parameter
determines the background color of the text box.</p>
<p>Note: The image is modified in-place. No new image is created.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>img</strong> – Image to which the text overlay will be added.</p></li>
<li><p><strong>text</strong> – Text to be displayed.</p></li>
<li><p><strong>pos</strong> – Position of the top-left corner of the text overlay.</p></li>
<li><p><strong>scale</strong> – Scale factor for the text size (default: 0.5).</p></li>
<li><p><strong>font_color</strong> – Color of the text (default: white).</p></li>
<li><p><strong>bg_color</strong> – Background color of the text box (default: black).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-deeplearningtools.helpers.tensor_msg_io">
<span id="deeplearningtools-helpers-tensor-msg-io-module"></span><h2>deeplearningtools.helpers.tensor_msg_io module<a class="headerlink" href="#module-deeplearningtools.helpers.tensor_msg_io" title="Permalink to this heading">#</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.tensor_msg_io.decode_multitensor_proto">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.tensor_msg_io.</span></span><span class="sig-name descname"><span class="pre">decode_multitensor_proto</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_feature_descriptions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">example_proto</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/tensor_msg_io.html#decode_multitensor_proto"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.tensor_msg_io.decode_multitensor_proto" title="Permalink to this definition">#</a></dt>
<dd><p>Decode a tf.train.Example, supposing its structure is known.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>data_feature_descriptions</strong> (<em>tf.Tensor</em>) – A dataset to be serialized.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Create a dictionary describing the expected features.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.tensor_msg_io.decode_tensor_proto">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.tensor_msg_io.</span></span><span class="sig-name descname"><span class="pre">decode_tensor_proto</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">example_proto</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/tensor_msg_io.html#decode_tensor_proto"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.tensor_msg_io.decode_tensor_proto" title="Permalink to this definition">#</a></dt>
<dd><p>Decode a tf.train.Example, supposing its structure is a simple tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>example_proto</strong> (<em>tf.Tensor</em>) – A dataset to be serialized.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dictionary describing the expected features.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.tensor_msg_io.decode_tensor_with_label_example">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.tensor_msg_io.</span></span><span class="sig-name descname"><span class="pre">decode_tensor_with_label_example</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">example_proto</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">tf.float32</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/tensor_msg_io.html#decode_tensor_with_label_example"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.tensor_msg_io.decode_tensor_with_label_example" title="Permalink to this definition">#</a></dt>
<dd><p>Decode a tf.train.Example, supposing its structure is known.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>example_proto</strong> (<em>tf.Tensor</em>) – Input tensor to be serialized.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Create a dictionary describing the expected features.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.tensor_msg_io.get_data_label_features_from_dataset">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.tensor_msg_io.</span></span><span class="sig-name descname"><span class="pre">get_data_label_features_from_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/tensor_msg_io.html#get_data_label_features_from_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.tensor_msg_io.get_data_label_features_from_dataset" title="Permalink to this definition">#</a></dt>
<dd><p>Construct a dictionnary of feature description to decode serialized tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>dataset</strong> (<em>tf.Tensor</em>) – A dataset to be serialized.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Create a dictionary describing the expected features.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.tensor_msg_io.serialize_float_with_text_label">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.tensor_msg_io.</span></span><span class="sig-name descname"><span class="pre">serialize_float_with_text_label</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/tensor_msg_io.html#serialize_float_with_text_label"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.tensor_msg_io.serialize_float_with_text_label" title="Permalink to this definition">#</a></dt>
<dd><p>Creates a tf.train.Example string message ready to be written to a file or sent as a message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>values</strong> (<em>list</em><em>[</em><em>float</em><em>]</em>) – The list of floating-point values to be serialized.</p></li>
<li><p><strong>label</strong> (<em>str</em>) – The text label associated with the values.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dictionary mapping the feature name to the tf.train.Example-compatible.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.tensor_msg_io.serialize_image_float_example">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.tensor_msg_io.</span></span><span class="sig-name descname"><span class="pre">serialize_image_float_example</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/tensor_msg_io.html#serialize_image_float_example"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.tensor_msg_io.serialize_image_float_example" title="Permalink to this definition">#</a></dt>
<dd><p>Creates a tf.train.Example string message ready to be written to a file or sent as a message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image_tensor</strong> (<em>tf.Tensor</em>) – The image tensor to be serialized.</p></li>
<li><p><strong>label_id</strong> (<em>str</em>) – The label associated with the image (optional).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dictionary mapping the feature name to the tf.train.Example-compatible.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.tensor_msg_io.serialize_tensor">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.tensor_msg_io.</span></span><span class="sig-name descname"><span class="pre">serialize_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/tensor_msg_io.html#serialize_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.tensor_msg_io.serialize_tensor" title="Permalink to this definition">#</a></dt>
<dd><p>Simply serialize a single tensor as a tf.Example.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>tensor</strong> (<em>tf.Tensor</em>) – A tensor to be serialized.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Create a dictionary describing the expected features.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.tensor_msg_io.serialize_tensor_label_example">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.tensor_msg_io.</span></span><span class="sig-name descname"><span class="pre">serialize_tensor_label_example</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/tensor_msg_io.html#serialize_tensor_label_example"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.tensor_msg_io.serialize_tensor_label_example" title="Permalink to this definition">#</a></dt>
<dd><p>Creates a tf.train.Example string message ready to be written to a file or sent as a message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensor</strong> (<em>tf.Tensor</em>) – The tensor to be serialized.</p></li>
<li><p><strong>label</strong> (<em>str</em>) – The label associated with the tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dictionary mapping the feature name to the tf.train.Example-compatible.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.tensor_msg_io.serialize_tensor_with_label">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.tensor_msg_io.</span></span><span class="sig-name descname"><span class="pre">serialize_tensor_with_label</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/tensor_msg_io.html#serialize_tensor_with_label"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.tensor_msg_io.serialize_tensor_with_label" title="Permalink to this definition">#</a></dt>
<dd><p>Creates a tf.train.Example string message ready to be written to a file or sent as a message.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensor</strong> (<em>tf.Tensor</em>) – Input tensor to be serialized.</p></li>
<li><p><strong>label</strong> (<em>str</em>) – Corresponding label associated with the tensor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Create a dictionary describing the expected features.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-deeplearningtools.helpers.tfrecords_io">
<span id="deeplearningtools-helpers-tfrecords-io-module"></span><h2>deeplearningtools.helpers.tfrecords_io module<a class="headerlink" href="#module-deeplearningtools.helpers.tfrecords_io" title="Permalink to this heading">#</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.tfrecords_io.display_image_tfrecords_dataset">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.tfrecords_io.</span></span><span class="sig-name descname"><span class="pre">display_image_tfrecords_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filename</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'test_dataset.tfrecords'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/tfrecords_io.html#display_image_tfrecords_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.tfrecords_io.display_image_tfrecords_dataset" title="Permalink to this definition">#</a></dt>
<dd><p>Load a dataset from a TFRecords file and display the recorded samples.</p>
<p>Suppose a dataset pointed by files ‘test_dataset.tfrecords’ exists, load it and display the recorded samples_saving_queuet</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>filename</strong> (<em>str</em>) – Path to the TFRecords file containing the dataset. (default: ‘test_dataset.tfrecords’)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.tfrecords_io.image_tfrecords_dataset">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.tfrecords_io.</span></span><span class="sig-name descname"><span class="pre">image_tfrecords_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filename</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hasLabels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/tfrecords_io.html#image_tfrecords_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.tfrecords_io.image_tfrecords_dataset" title="Permalink to this definition">#</a></dt>
<dd><p>Assuming a set of tfrecords file is pointed by filename, ex:’images.tfrecords’,
create a data provider that loads them for training/testing models</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filename</strong> – A path to the tfrecord files.</p></li>
<li><p><strong>haslabel</strong> – A boolean, false by default that specifies if an iteger label is expected or not</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tf.data.Dataset WITHOUT PREFETCH NOR BATCH, specify your own</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="deeplearningtools.helpers.tfrecords_io.write_image_dataset_no_display">
<span class="sig-prename descclassname"><span class="pre">deeplearningtools.helpers.tfrecords_io.</span></span><span class="sig-name descname"><span class="pre">write_image_dataset_no_display</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">images_dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_out</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'demo_image_dataset.tfrecords'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/deeplearningtools/helpers/tfrecords_io.html#write_image_dataset_no_display"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#deeplearningtools.helpers.tfrecords_io.write_image_dataset_no_display" title="Permalink to this definition">#</a></dt>
<dd><p>Add serialization node to the dataprovider and write the dataset directly.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>images_dataset</strong> (<em>tf.data.Dataset</em>) – The image dataset to be written.</p></li>
<li><p><strong>file_out</strong> (<em>str</em>) – The output path for the TFRecords file. (default: “demo_image_dataset.tfrecords”)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="reference_tools.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">deeplearningtools.tools subpackage</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="unit_test.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Test script</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023, Alexandre Benoit
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">deeplearningtools.helpers subpackage</a><ul>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-deeplearningtools.helpers.alignment">deeplearningtools.helpers.alignment module</a><ul>
<li><a class="reference internal" href="#deeplearningtools.helpers.alignment.align_network"><code class="docutils literal notranslate"><span class="pre">align_network()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.alignment.gradient"><code class="docutils literal notranslate"><span class="pre">gradient()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.alignment.l1"><code class="docutils literal notranslate"><span class="pre">l1()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.alignment.l2"><code class="docutils literal notranslate"><span class="pre">l2()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.alignment.pearson"><code class="docutils literal notranslate"><span class="pre">pearson()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.alignment.pearson_cost"><code class="docutils literal notranslate"><span class="pre">pearson_cost()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.alignment.pearson_sorted"><code class="docutils literal notranslate"><span class="pre">pearson_sorted()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.alignment.spearman"><code class="docutils literal notranslate"><span class="pre">spearman()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.alignment.spearman_cost"><code class="docutils literal notranslate"><span class="pre">spearman_cost()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.alignment.spearman_sorted"><code class="docutils literal notranslate"><span class="pre">spearman_sorted()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.alignment.stack"><code class="docutils literal notranslate"><span class="pre">stack()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-deeplearningtools.helpers.attention">deeplearningtools.helpers.attention module</a><ul>
<li><a class="reference internal" href="#deeplearningtools.helpers.attention.aconv"><code class="docutils literal notranslate"><span class="pre">aconv()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.attention.aconv2"><code class="docutils literal notranslate"><span class="pre">aconv2()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.attention.dual_attention"><code class="docutils literal notranslate"><span class="pre">dual_attention()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.attention.spatial_attention"><code class="docutils literal notranslate"><span class="pre">spatial_attention()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.attention.squeeze_excitation"><code class="docutils literal notranslate"><span class="pre">squeeze_excitation()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-deeplearningtools.helpers.distance_network">deeplearningtools.helpers.distance_network module</a><ul>
<li><a class="reference internal" href="#deeplearningtools.helpers.distance_network.cosine_distance"><code class="docutils literal notranslate"><span class="pre">cosine_distance()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.distance_network.cosine_similarity"><code class="docutils literal notranslate"><span class="pre">cosine_similarity()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.distance_network.deep_relative_trust"><code class="docutils literal notranslate"><span class="pre">deep_relative_trust()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.distance_network.deep_relative_trust_similarity"><code class="docutils literal notranslate"><span class="pre">deep_relative_trust_similarity()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.distance_network.euclidean_norm"><code class="docutils literal notranslate"><span class="pre">euclidean_norm()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.distance_network.flatten"><code class="docutils literal notranslate"><span class="pre">flatten()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.distance_network.l1"><code class="docutils literal notranslate"><span class="pre">l1()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.distance_network.l2"><code class="docutils literal notranslate"><span class="pre">l2()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.distance_network.percentage_different_signs_gradients"><code class="docutils literal notranslate"><span class="pre">percentage_different_signs_gradients()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-deeplearningtools.helpers.federated">deeplearningtools.helpers.federated module</a><ul>
<li><a class="reference internal" href="#deeplearningtools.helpers.federated.FlClient"><code class="docutils literal notranslate"><span class="pre">FlClient</span></code></a><ul>
<li><a class="reference internal" href="#deeplearningtools.helpers.federated.FlClient.evaluate"><code class="docutils literal notranslate"><span class="pre">FlClient.evaluate()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.federated.FlClient.fit"><code class="docutils literal notranslate"><span class="pre">FlClient.fit()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.federated.FlClient.get_parameters"><code class="docutils literal notranslate"><span class="pre">FlClient.get_parameters()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#deeplearningtools.helpers.federated.FlowerClient_"><code class="docutils literal notranslate"><span class="pre">FlowerClient_</span></code></a><ul>
<li><a class="reference internal" href="#deeplearningtools.helpers.federated.FlowerClient_.evaluate"><code class="docutils literal notranslate"><span class="pre">FlowerClient_.evaluate()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.federated.FlowerClient_.fit"><code class="docutils literal notranslate"><span class="pre">FlowerClient_.fit()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.federated.FlowerClient_.get_parameters"><code class="docutils literal notranslate"><span class="pre">FlowerClient_.get_parameters()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#module-deeplearningtools.helpers.federated_utils.flclient">deeplearningtools.helpers.federated_utils.flclient module</a><ul>
<li><a class="reference internal" href="#deeplearningtools.helpers.federated_utils.flclient.FlClient"><code class="docutils literal notranslate"><span class="pre">FlClient</span></code></a><ul>
<li><a class="reference internal" href="#deeplearningtools.helpers.federated_utils.flclient.FlClient.evaluate"><code class="docutils literal notranslate"><span class="pre">FlClient.evaluate()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.federated_utils.flclient.FlClient.fit"><code class="docutils literal notranslate"><span class="pre">FlClient.fit()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.federated_utils.flclient.FlClient.get_client_config_filename"><code class="docutils literal notranslate"><span class="pre">FlClient.get_client_config_filename()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.federated_utils.flclient.FlClient.get_parameters"><code class="docutils literal notranslate"><span class="pre">FlClient.get_parameters()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.federated_utils.flclient.FlClient.load_restart_config"><code class="docutils literal notranslate"><span class="pre">FlClient.load_restart_config()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.federated_utils.flclient.FlClient.write_restart_config"><code class="docutils literal notranslate"><span class="pre">FlClient.write_restart_config()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#deeplearningtools.helpers.federated_utils.flclient.FlowerClient_"><code class="docutils literal notranslate"><span class="pre">FlowerClient_</span></code></a><ul>
<li><a class="reference internal" href="#deeplearningtools.helpers.federated_utils.flclient.FlowerClient_.evaluate"><code class="docutils literal notranslate"><span class="pre">FlowerClient_.evaluate()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.federated_utils.flclient.FlowerClient_.fit"><code class="docutils literal notranslate"><span class="pre">FlowerClient_.fit()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.federated_utils.flclient.FlowerClient_.get_parameters"><code class="docutils literal notranslate"><span class="pre">FlowerClient_.get_parameters()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#module-deeplearningtools.helpers.file_io">deeplearningtools.helpers.file_io module</a><ul>
<li><a class="reference internal" href="#deeplearningtools.helpers.file_io.count_lines"><code class="docutils literal notranslate"><span class="pre">count_lines()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.file_io.extractFilenames"><code class="docutils literal notranslate"><span class="pre">extractFilenames()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-deeplearningtools.helpers.kafka_io">deeplearningtools.helpers.kafka_io module</a><ul>
<li><a class="reference internal" href="#deeplearningtools.helpers.kafka_io.KafkaIO"><code class="docutils literal notranslate"><span class="pre">KafkaIO</span></code></a><ul>
<li><a class="reference internal" href="#deeplearningtools.helpers.kafka_io.KafkaIO.kafka_dataset_consumer_tf_basic"><code class="docutils literal notranslate"><span class="pre">KafkaIO.kafka_dataset_consumer_tf_basic()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.kafka_io.KafkaIO.kafka_dataset_consumer_tf_custom"><code class="docutils literal notranslate"><span class="pre">KafkaIO.kafka_dataset_consumer_tf_custom()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.kafka_io.KafkaIO.kafka_dataset_incremental_consumer_tf"><code class="docutils literal notranslate"><span class="pre">KafkaIO.kafka_dataset_incremental_consumer_tf()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.kafka_io.KafkaIO.kafka_producer_tf"><code class="docutils literal notranslate"><span class="pre">KafkaIO.kafka_producer_tf()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#deeplearningtools.helpers.kafka_io.error_callback"><code class="docutils literal notranslate"><span class="pre">error_callback()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-deeplearningtools.helpers.loss">deeplearningtools.helpers.loss module</a><ul>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.Regularizer_L1L2Ortho"><code class="docutils literal notranslate"><span class="pre">Regularizer_L1L2Ortho</span></code></a><ul>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.Regularizer_L1L2Ortho.get_config"><code class="docutils literal notranslate"><span class="pre">Regularizer_L1L2Ortho.get_config()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.Regularizer_None"><code class="docutils literal notranslate"><span class="pre">Regularizer_None</span></code></a><ul>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.Regularizer_None.get_config"><code class="docutils literal notranslate"><span class="pre">Regularizer_None.get_config()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.Regularizer_Spectral_Restricted_Isometry"><code class="docutils literal notranslate"><span class="pre">Regularizer_Spectral_Restricted_Isometry</span></code></a><ul>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.Regularizer_Spectral_Restricted_Isometry.get_config"><code class="docutils literal notranslate"><span class="pre">Regularizer_Spectral_Restricted_Isometry.get_config()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.Regularizer_soft_orthogonality"><code class="docutils literal notranslate"><span class="pre">Regularizer_soft_orthogonality</span></code></a><ul>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.Regularizer_soft_orthogonality.get_config"><code class="docutils literal notranslate"><span class="pre">Regularizer_soft_orthogonality.get_config()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.UncorrelatedFeaturesConstraint"><code class="docutils literal notranslate"><span class="pre">UncorrelatedFeaturesConstraint</span></code></a><ul>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.UncorrelatedFeaturesConstraint.get_covariance"><code class="docutils literal notranslate"><span class="pre">UncorrelatedFeaturesConstraint.get_covariance()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.UncorrelatedFeaturesConstraint.uncorrelated_feature"><code class="docutils literal notranslate"><span class="pre">UncorrelatedFeaturesConstraint.uncorrelated_feature()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.class_weights"><code class="docutils literal notranslate"><span class="pre">class_weights()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.discrepancy_slice_wasserstein"><code class="docutils literal notranslate"><span class="pre">discrepancy_slice_wasserstein()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.exponentialLogLoss"><code class="docutils literal notranslate"><span class="pre">exponentialLogLoss()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.focal_loss_softmax"><code class="docutils literal notranslate"><span class="pre">focal_loss_softmax()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.generateTheta"><code class="docutils literal notranslate"><span class="pre">generateTheta()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.generateZ_circle"><code class="docutils literal notranslate"><span class="pre">generateZ_circle()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.generateZ_ring"><code class="docutils literal notranslate"><span class="pre">generateZ_ring()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.get_IOgradient_norm_lipschitzPenalty"><code class="docutils literal notranslate"><span class="pre">get_IOgradient_norm_lipschitzPenalty()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.get_batch_flat_tensors"><code class="docutils literal notranslate"><span class="pre">get_batch_flat_tensors()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.get_per_sample_class_weights"><code class="docutils literal notranslate"><span class="pre">get_per_sample_class_weights()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.get_sample_class_probabilities"><code class="docutils literal notranslate"><span class="pre">get_sample_class_probabilities()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.kl_loss"><code class="docutils literal notranslate"><span class="pre">kl_loss()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.multi_loss"><code class="docutils literal notranslate"><span class="pre">multi_loss()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.multiclass_dice_loss_softmax"><code class="docutils literal notranslate"><span class="pre">multiclass_dice_loss_softmax()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.multiclass_jaccard_loss_softmax"><code class="docutils literal notranslate"><span class="pre">multiclass_jaccard_loss_softmax()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.multiclass_lovasz_loss_softmax"><code class="docutils literal notranslate"><span class="pre">multiclass_lovasz_loss_softmax()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.multiclass_tversky_loss_softmax"><code class="docutils literal notranslate"><span class="pre">multiclass_tversky_loss_softmax()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.preds_labels_preprocess_softmax_flatten"><code class="docutils literal notranslate"><span class="pre">preds_labels_preprocess_softmax_flatten()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.reconstruction_loss_BCE"><code class="docutils literal notranslate"><span class="pre">reconstruction_loss_BCE()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.reconstruction_loss_BCE_soft"><code class="docutils literal notranslate"><span class="pre">reconstruction_loss_BCE_soft()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.reconstruction_loss_L1"><code class="docutils literal notranslate"><span class="pre">reconstruction_loss_L1()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.reconstruction_loss_MSE"><code class="docutils literal notranslate"><span class="pre">reconstruction_loss_MSE()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.slicedWasserteinLoss_single"><code class="docutils literal notranslate"><span class="pre">slicedWasserteinLoss_single()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.smooth_labels"><code class="docutils literal notranslate"><span class="pre">smooth_labels()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.swae_loss"><code class="docutils literal notranslate"><span class="pre">swae_loss()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.tensor_gram_matrix"><code class="docutils literal notranslate"><span class="pre">tensor_gram_matrix()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.loss.weighted_xcrosspow_loss_softmax"><code class="docutils literal notranslate"><span class="pre">weighted_xcrosspow_loss_softmax()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-deeplearningtools.helpers.model_serving_tools">deeplearningtools.helpers.model_serving_tools module</a><ul>
<li><a class="reference internal" href="#deeplearningtools.helpers.model_serving_tools.WaitForServerReady"><code class="docutils literal notranslate"><span class="pre">WaitForServerReady()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model_serving_tools.decode_model_serving_answer"><code class="docutils literal notranslate"><span class="pre">decode_model_serving_answer()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model_serving_tools.deserialize_srv_answer_uint8"><code class="docutils literal notranslate"><span class="pre">deserialize_srv_answer_uint8()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model_serving_tools.deserialize_srv_answer_uint8_vfrombuffer"><code class="docutils literal notranslate"><span class="pre">deserialize_srv_answer_uint8_vfrombuffer()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model_serving_tools.generate_single_request"><code class="docutils literal notranslate"><span class="pre">generate_single_request()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model_serving_tools.get_model_server_cfg"><code class="docutils literal notranslate"><span class="pre">get_model_server_cfg()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model_serving_tools.get_served_model_info"><code class="docutils literal notranslate"><span class="pre">get_served_model_info()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model_serving_tools.setup_model_server_connexion"><code class="docutils literal notranslate"><span class="pre">setup_model_server_connexion()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-deeplearningtools.helpers.model_tcn">deeplearningtools.helpers.model_tcn module</a><ul>
<li><a class="reference internal" href="#deeplearningtools.helpers.model_tcn.ResidualBlock"><code class="docutils literal notranslate"><span class="pre">ResidualBlock</span></code></a><ul>
<li><a class="reference internal" href="#deeplearningtools.helpers.model_tcn.ResidualBlock.build"><code class="docutils literal notranslate"><span class="pre">ResidualBlock.build()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model_tcn.ResidualBlock.call"><code class="docutils literal notranslate"><span class="pre">ResidualBlock.call()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model_tcn.ResidualBlock.compute_output_shape"><code class="docutils literal notranslate"><span class="pre">ResidualBlock.compute_output_shape()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model_tcn.TCN"><code class="docutils literal notranslate"><span class="pre">TCN</span></code></a><ul>
<li><a class="reference internal" href="#deeplearningtools.helpers.model_tcn.TCN.build"><code class="docutils literal notranslate"><span class="pre">TCN.build()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model_tcn.TCN.call"><code class="docutils literal notranslate"><span class="pre">TCN.call()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model_tcn.TCN.compute_output_shape"><code class="docutils literal notranslate"><span class="pre">TCN.compute_output_shape()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model_tcn.TCN.get_config"><code class="docutils literal notranslate"><span class="pre">TCN.get_config()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model_tcn.TCN.receptive_field"><code class="docutils literal notranslate"><span class="pre">TCN.receptive_field</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model_tcn.adjust_dilations"><code class="docutils literal notranslate"><span class="pre">adjust_dilations()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model_tcn.compiled_tcn"><code class="docutils literal notranslate"><span class="pre">compiled_tcn()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model_tcn.is_power_of_two"><code class="docutils literal notranslate"><span class="pre">is_power_of_two()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model_tcn.tcn_full_summary"><code class="docutils literal notranslate"><span class="pre">tcn_full_summary()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-deeplearningtools.helpers.model">deeplearningtools.helpers.model module</a><ul>
<li><a class="reference internal" href="#deeplearningtools.helpers.model.ConcreteDropout"><code class="docutils literal notranslate"><span class="pre">ConcreteDropout</span></code></a><ul>
<li><a class="reference internal" href="#deeplearningtools.helpers.model.ConcreteDropout.build"><code class="docutils literal notranslate"><span class="pre">ConcreteDropout.build()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model.ConcreteDropout.call"><code class="docutils literal notranslate"><span class="pre">ConcreteDropout.call()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model.ConcreteDropout.compute_output_shape"><code class="docutils literal notranslate"><span class="pre">ConcreteDropout.compute_output_shape()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model.ConcreteDropout.concrete_dropout"><code class="docutils literal notranslate"><span class="pre">ConcreteDropout.concrete_dropout()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model.ReplicatedOrthogonalInitialize"><code class="docutils literal notranslate"><span class="pre">ReplicatedOrthogonalInitialize</span></code></a><ul>
<li><a class="reference internal" href="#deeplearningtools.helpers.model.ReplicatedOrthogonalInitialize.get_config"><code class="docutils literal notranslate"><span class="pre">ReplicatedOrthogonalInitialize.get_config()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model.SubpixelConv2D"><code class="docutils literal notranslate"><span class="pre">SubpixelConv2D</span></code></a><ul>
<li><a class="reference internal" href="#deeplearningtools.helpers.model.SubpixelConv2D.get_config"><code class="docutils literal notranslate"><span class="pre">SubpixelConv2D.get_config()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model.atrous_Spatial_pyramid_pooling"><code class="docutils literal notranslate"><span class="pre">atrous_Spatial_pyramid_pooling()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model.concrete_dropout"><code class="docutils literal notranslate"><span class="pre">concrete_dropout()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model.load_model"><code class="docutils literal notranslate"><span class="pre">load_model()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model.make_circle_cloud_dataset"><code class="docutils literal notranslate"><span class="pre">make_circle_cloud_dataset()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model.test_ReplicatedOrthogonalInitialize"><code class="docutils literal notranslate"><span class="pre">test_ReplicatedOrthogonalInitialize()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model.track_gradients"><code class="docutils literal notranslate"><span class="pre">track_gradients()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.model.track_weights_change"><code class="docutils literal notranslate"><span class="pre">track_weights_change()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-deeplearningtools.helpers.opencv_tools">deeplearningtools.helpers.opencv_tools module</a><ul>
<li><a class="reference internal" href="#deeplearningtools.helpers.opencv_tools.add_text_overlay"><code class="docutils literal notranslate"><span class="pre">add_text_overlay()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-deeplearningtools.helpers.tensor_msg_io">deeplearningtools.helpers.tensor_msg_io module</a><ul>
<li><a class="reference internal" href="#deeplearningtools.helpers.tensor_msg_io.decode_multitensor_proto"><code class="docutils literal notranslate"><span class="pre">decode_multitensor_proto()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.tensor_msg_io.decode_tensor_proto"><code class="docutils literal notranslate"><span class="pre">decode_tensor_proto()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.tensor_msg_io.decode_tensor_with_label_example"><code class="docutils literal notranslate"><span class="pre">decode_tensor_with_label_example()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.tensor_msg_io.get_data_label_features_from_dataset"><code class="docutils literal notranslate"><span class="pre">get_data_label_features_from_dataset()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.tensor_msg_io.serialize_float_with_text_label"><code class="docutils literal notranslate"><span class="pre">serialize_float_with_text_label()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.tensor_msg_io.serialize_image_float_example"><code class="docutils literal notranslate"><span class="pre">serialize_image_float_example()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.tensor_msg_io.serialize_tensor"><code class="docutils literal notranslate"><span class="pre">serialize_tensor()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.tensor_msg_io.serialize_tensor_label_example"><code class="docutils literal notranslate"><span class="pre">serialize_tensor_label_example()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.tensor_msg_io.serialize_tensor_with_label"><code class="docutils literal notranslate"><span class="pre">serialize_tensor_with_label()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-deeplearningtools.helpers.tfrecords_io">deeplearningtools.helpers.tfrecords_io module</a><ul>
<li><a class="reference internal" href="#deeplearningtools.helpers.tfrecords_io.display_image_tfrecords_dataset"><code class="docutils literal notranslate"><span class="pre">display_image_tfrecords_dataset()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.tfrecords_io.image_tfrecords_dataset"><code class="docutils literal notranslate"><span class="pre">image_tfrecords_dataset()</span></code></a></li>
<li><a class="reference internal" href="#deeplearningtools.helpers.tfrecords_io.write_image_dataset_no_display"><code class="docutils literal notranslate"><span class="pre">write_image_dataset_no_display()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/scripts/furo.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    </body>
</html>